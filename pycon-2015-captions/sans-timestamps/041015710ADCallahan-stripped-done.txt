OUR NEXT TALKER IS DAN CALLAHAN AND HE'S GOING TO
BE TELLING US ABOUT RUNNING PYTHON APPS ON
COREOS.
>> THANK YOU.
MIC?
THERE WE GO.
SO, ANY NAME IS DAN CALLAHAN, I WORK IN DEVELOPER
RELATIONS FOR MOZILLA, YOU CAN FIND ME ON
TWITTER@CALLAHAN.
TWO YEARS AGO, DOCKER GOT RELEASED AND EVER
SINCE, AN ENORMOUS BUZZ AND EXCITEMENT ABOUT
CONTAINERIZATION ON LINUX.
I WON'T TALK ABOUT DOCKER TODAY.
THERE IS AN ENTIRE TALK ON IT TOMORROW, GO TO IT.
WHAT I WANT TO TALK ABOUT MORE IS THE IMPACT THAT
THIS INTEREST IN CONTAINERIZATION RECEIVING ON
THE REST OF OUR BACK-END SERVER STACK.
SO WHAT DOES CONTAIN JURYIZATION CHANGE FOR THE
WAY WE ARCHITECT OUR HOST MACHINES?
I'M GOING TO LOOK AT THIS BY EXAMINING A LINUX
DISTRIBUTION CALLED COREOS WHICH WAS RELEASED
ABOUT A YEAR AND A HALF AGO AND IT'S DESIGNED
FROM THE GROUND UP TO RUN CONTAINERS.
NOT THAT YOU NEED A SPECIAL -- TO RUN CONTAINERS
BUT BY LOOKING AT A DISTRO THAT WAS DESIGNED AS A
GREENFIELD EXPERIMENT AND WHAT AN IDEAL HOST FOR
CONTAINERS WOULD LOOK LIKE, WE CAN SEE THINGS
TODAY THAT WILL BECOME BEST PRACTICES IN THE NEXT
FEW YEARS.
FROM THOSE OF YOU FROM THE BAY AREA, GREEN IS
GOING TO BE STARTED ON MONDAY, SO BE READY FOR
THAT WHEN YOU GET BACK FROM PYCON.
WHAT ARE WE TRYING TO SOLVE HERE?
WHY ARE PEOPLE EXCITED ABOUT CONTAINERS?
I DON'T DO OPS, I HAVE WEEKEND PROJECTS, I WANT
TO DEPLOY THEM SOMEWHERE, I WANT A PLATFORM THAT
WILL STAY UPDATED AUTOMATICALLY, I WANT THAT
PLATFORM TO STAY UPDATEd in a day that won't
break my apps by, you know, upgrading a
dependency out from under me and I want a
platform that will survive outages so it would be
really fantastic if I get a server and I pulled
the plug on it, if I can trust that my
applications will keep running somewhere else,
because if we have those three things, I can be
lazy and that's ultimately what I'm looking for,
right?
But to get there, we need something declarative,
we need the ability to say -- declarative, we
NEED SOMETHING TO SAY ALWAYS KEEP TWO OF THESE
RUNNING AND DIDN'T PUT THEM ON THE SAME MACHINE.
I COULD PROBABLY COBBLE SOMETHING TOGETHER THAT
GETS ME THERE BUT AT A CERTAIN POINT, YOU START
KIND OF COLLAPSING UNDER THE WEIGHT OF ALL THOSE
ORCHESTRATION AND THIS KIND OF RUBE GOLDBERG
MACHINE OF WHAT'S ONLINE, WHAT'S OFFLINE AND YOU
DON'T WANT TO TOUCH YOUR SERVERS AND YOU GOT
MONTHS AND MONTHS WITH THIS FAITH-BASED DEV-OPS
THAT I TRUST THINGS WILL BE OKAY AND THEN HEART
BLEED HAPPENS, AND ALL OF THAT TECHNICAL DECK
COMES CRUSHING DOWN.
SO THE WAY WE GET ON THE OF THAT MORASS, FOR
HOBBYISTS LIKE ME, IS MOVING TO SOMETHING
DECLARATIVE, WHERE WE CAN DEFINE THE STATE WE
WANT AND TRUST OTHER SYSTEMS ARE GOING TO MAKE
THAT REALTY.
TO DO THAT, WE NEEDS NEW TECHNOLOGY AND WE NEED
THAT -- NOT BRAND-NEW TECHNOLOGY.
THIS SORT OF STUFF HAS BEEN THE NORM INSIDE
GOOGLE AND AMAZON, Facebook, FOR A WHILE, BUT
WE NEED SOMEBODY TO TAKE GOOGLE'S SECRET SAUCE
AND PACKAGE IT IN A WAY WE CAN RUN IT ON OUR OWN
SERVERS.
IN A SENSE, THAT'S WHAT COREOS IS DOING SO, WE
NEED INNOVATION IN FOUR KEY AREAS.
WE SEED A BETTER WAY TO HANDLE SYSTEM IS UPDATES.
TWO, WE NEED A WAY TO ISOLATE OUR APPLICATIONS
FROM THE HOST ENVIRONMENT.
WE NEED A WAY TO CLUSTER OUR SERVERS TOGETHER SO
THAT THEY CAN BE REASONED ABOUT AS A SINGLE
LOGICAL UNIT.
AND WE NEED A WAY TO DISTRIBUTE TASKS AMONGST THE
CLUSTER.
SO IN THIS TALK, I'M GOING TO LOOK AT HOW COREOS
SOLVES THOSE PROBLEMS.
FOR UPDATES, WE'RE DOING TO LOOK AT FAST PATCH.
FOR CONTAINERS FOR APPLICATION ISOLATION, LOOK AT
DOCTOR AND ROCKET.
WE'LL LOOK AT A PROJECT CALLED ETCD, AND FOR
SCHEDULING, THE JOB OF DISTRIBUTING TASKS WE'LL
LOOK AT FLEET AND...
[ Audio Indiscernible ]
SO WE'LL LOOK AT EACH OFF THESE IN TURN AND SEE
WHAT THE PROBLEM IS AND WHAT THEY'RE SOLVING AND
WHAT THEY MEAN FOR SERVERS AND OF OUR
APPLICATIONS.
AND ALL OF THIS IS FREE AND OPEN SOURCE SOFTWARE,
SO ONE OF THE THINGS THAT I REALLY ADMIRE ABOUT
COREOS AS A COMPANY, THEY'VE CONTRIBUTED THINGS
LIKE ETCD AND FLEET AS TRULY COMMERCIAL PROJECTS.
YOU CAN STAND THIS UP TODAY WITHOUT HAVING TO
ACCEPT PROPRIETARY SOFTWARE, WITHOUT HAVING TO
PAY A DIME.
REALLY FANTASTIC.
SO DELETES START WITH SYSTEM UPDATES.
COREOS USES A SYSTEM CALLED FAST PATCH.
WHAT THEY'RE TRYING TO DO IS DECREASE THE GAP
BETWEEN WHEN A PATCH BECOMES AVAILABLE AND WHEN
IT BECOMES APPLIED TO YOUR SERVERS.
BECAUSE STAYING UP TO DATE IS KEY TO GOOD
SECURITY.
AS SOON AS A VULNERABLE IS KNOWN, A PATCH IS MADE
AVAILABLE, YOU'RE BASICALLY RACING, DOZENS OF
OTHER PEOPLE IN THE WORLD TO SEE IF YOU CAN PATCH
YOUR SERVERS BEFORE THEY CAN DEVELOP AN AUTOMATED
EXPLOIT.
SO ANYTHING YOU CAN DO TO GO FROM PATCH AVAILABLE
TO PATCH APPLIED AS QUICKLY AS POSSIBLE, THE
BETTER, SO THE FIRST THING COREOS DOES IS THEY'VE
ADOPTED A BROWSER-STYLE UPDATE MODEL SO YOU HAVE
CHANNELS, YOU CAN SAY I WANT THE ALPHA, BETA OR
STABLE RELEASE OF MY OPERATING SYSTEM.
IN THE BACKGROUND, UPDATES GET DOWNLOADED
OPPORTUNISTICALLY, SO A NEW VERSION OF COREOS
COMES OUT, IT'S DOWNLOADED.
NEXT TIME YOU REBOOT, IT'S APPLIED.
THE OTHER THING THAT COREOS DOES, THEY TREAT THE
ENTIRE SYSTEM AS A SINGLE UNIT FOR THE PURPOSE OF
UPDATES.
SO WHAT THIS LOOKS LIKE IS WHEN YOU BOOT INTO A
COREOS MACHINE, YOU HAVE THREE PARTITIONS, AN A
PARTITION, AND A B, BOTH OF WHICH HOLD THE COREOS
SYSTEM AND YOU HAVE A DATA PARTITION FOR YOUR OWN
STUFF.
THESE ARE MOUNTED ADD READ-ONLY SO YOU CAN
FLIP-FLOP BETWEEN THEM.
WHEN AN UPDATE BECOMES AVAILABLE, A DAMON THAT
HAS NICE LIMITS ON HOW MUCH BAND WIDTH AND CPU TO
USE WILL DOWNLOAD THE UPDATES, APPLY IT TO THE
PARTITION.
THE UPDATES ARE EFFECTIVELY ENTIRE SYSTEM IMAGES,
YOU GET A WHOLE NEW ISO BASICALLY EVERY TIME AN
UPDATE COMES OUT.
THAT UPDATE GETS APPLIED AND THE NEXT TIME YOU
REBOOT, YOU'RE RUNNING SYSTEM B WITH THAT UPDATE
AND YOU HAVE YOUR DATA IN THE DATA PARTITION.
THIS HAS A COUPLE OF REALLY NICE PROPERTIES.
ONE IS THAT FOR WHATEVER REASON, IF THAT UPDATE'S
BAD, YOU CAN REBOOT AGAIN AND YOU'RE BACK INTO A,
INTO A KNOWN GOOD STATE, RIGHT?
SOME HAVE UPDATES THAT ARE RECOVERABLE, YOU CAN
ROLL BACK ON.
THE OTHER NICE PROPERTY OF THE SYSTEM IS THAT THE
UPDATES ARE AUTUMN MICK AND WHAT THAT MEANS IS
INSTEAD OF GOING PACKAGE BY PACKAGE, LIKE YUM,
WHERE A POWER OUTAGE HAPPENED HALFWAY THROUGH
YOUR UPDATE, YOU MIGHT BE LIFT IN AN INCONSISTENT
STATE.
WITH COREOS EITHER THE WHOLE UPDATE GOT APPLIED
OR NOTHING, WHICH IS REALLY IMPORTANT WHEN YOU'RE
DEALING WITH AUTOMATIC REBOOTS OF YOUR SERVERS,
RIGHT?
YOU WANT TO KNOW THAT YOU'RE NOT GOING TO HAVE AN
ADVERSE EVENT LEAVE YOU COMPLETELY BROKEN.
SO WE'VE GOT A SERVER, IT'S RUNNING OUR APP.
THE SERVER IS RUNNING COREOS.
AND YOU'RE PROBABLY THINKING TO YOURSELF, WAIT A
SECOND, DAN, MY SERVER IS REBOOTING ON ITS OWN,
HOW DO I KEEP MY APP ONLINE?
NAIVE ANSWER IS, LET'S JUST ADD ANOTHER SERVER,
RIGHT?
WE HAVE TWO SERVERS, WE SHOULD BE OKAY, EXCEPT
WHAT'S CAUSING THE SERVER TO REBOOT?
AN UPDATE BECOMES AVAILABLE, THE SERVER NOTICES
IT, DOWNLOADS IT, BOTH THE SERVERS WILL SIGH THE
UPDATE AT THE SAME TIME.
SO NOW BOTH YOUR SERVERS ARE REBOOTING AT THE
SAME TIME.
HOW DO YOU KEEP YOUR APP ONLINE?
[ Laughter ]
RIGHT, WE CAN JUST ADD INCREASINGLY MORE SERVERS
UNTIL, LIKE, WE PROBABLY WON'T HAVE THEM ALL OFF
AT THE SAME TIME.
A BETTER SOLUTION MIGHT BE TO INTRODUCE
CONSENSUS, INTRODUCE INCLUDES TIERING AND WE'RE
GOING TO DO THAT WITH A TOOL CALLED ETCD, BUNDLED
WITH COREOS.
IT'S A KEY VALUE STORE AND IT GIVES US A PLACE
WHERE IF WE STAND UP A THIRD CLUSTER, IT'S A
PLACE TO STORE META DATA ABOUT THE CLUSTER.
SO WE HAVE THREE SERVERS, ONE FOR ETCD AND TWO
FOR THE APP.
ON TOP OF THIS CENTRAL PLACE OF HISTORIC
CONFIGURATION, COREOS BUILDS A TOOL CALLED LOCK
SCHMIDT, SO WHENEVER A SERVER WANTS TO UPDATES TO
REBOOT ITSELF, IT HAS TO ACQUIRE A LOCK FROM
ETCD, AND WHEN IT COMES BACK UP AFTER THE UPDATE,
IT RELATES THE LOCK.
SO THIS MEANS YOU CAN GOVERN THE RATE AT WHICH
UPDATES ROLL OUT ACROSS YOUR CLUSTER BY LIMITING
THE NUMBER OF LOCKS AVAILABLE.
IT ALSO MEANS THAT IF AN UPDATE COMES OUT THAT'S
BAD THAT YOUR HARDWARE WON'T BOOT FROM, A SERVER
WILL GRAB A LOCK, ATTEMPT TO REBOOT, IT WON'T
COME BACK UP SO IT WILL NEVER RELEASE THAT LOCK
WHICH MEANS YOU CAN'T HAVE A CASCADING FAILURE
DUE TO A BAD UPDATE.
LET'S LOOK AT WHAT THAT LOOKS LIKE.
SO I'VE GOT TWO COREOS VIRTUAL MACHINES AND I'VE
GOT LOCKSMITH AND I CAN LOOK AT STATUS AND I SEE
THAT I HAVE ONE LOCK AVAILABLE OUT OF A MAXIMUM
OF ONE, SO I CAN GO AHEAD AND SAY, "LOCK."
IF I LOOK AT THE STATUS AGAIN, WE CAN SEE THIS
MACHINE HAS ACQUIRED A LOCK AND IS NOW CLEARED TO
REBOOT.
IF I TRY TO LOCK ON THIS OTHER MACHINE OR ACQUIRE
A LOCK OVER HERE...
I GET AN ERROR BECAUSE THERE AREN'T ANY MORE
LOCKS AVAILABLE.
THIS SERVER HAS TO RELEASE THE LOCK FIRST.
AND SO ALL THIS IS DOING IS WRITING AND READING
FROM A KEY IN ETCD.
SAY S FOR CURSIVE AND WE HAVE THIS LEAFLET HERE,
THAT IF WE SAY "ETCD CONTROL, GET JOBS, A JSON
DOCUMENT."
ZERO SUM AVAILABLE IS AVAILABLE WITH A MAXIMUM,
THIS MACHINE I.D. IS HOLDING IT.
SO WITH ETCD WE CAN COME OVER HERE AND SAY, WATCH
FOREVER.
THAT KEY.
AND NOW WE'LL BE NOTIFIED WHEN IT CHANGES.
SO IF I UNLOCK THIS SERVER, WE SEE THE UPDATED
DOCUMENT.
IF I RELOCK, SO REALLY NICE WAY TO GET NOTIFIED
OF CHANGES TO YOUR CLUSTER CONFIGURATION, RIGHT?
SO WHEN THE LOCK IS AVAILABLE, THE SERVER CAN GET
ONE.
REBOOT AND WE WOULD ALL BE IN A REALLY GOOD
PLACE.
DOES THIS SOLVE OUR PROBLEM OF OUR SERVERS
REBOOTING?
YES?
NO.
GUESS WHAT'S ALSO RUNNING COREOS, THE ETCD
SERVER.
THAT'S REBOOTING ON ITS OWN.
HOW DO I KEEP MY APP ONLINE?
RIGHT, ADD ANOTHER SERVER.
SO YOU MAY BE SENSING A THEME.
WE HAVE A SERVER, AND THEN WE WANT MORE.
AND YOU JUST KEEP GETTING MORE.
SO THE NICE THING ABOUT ETCD IS THAT WE HAVE THE
SINGLE POINT OF FAILURE TO GET AWAY FROM THAT,
R.THAT, WE NEED TO DISTRIBUTES THAT AND IT'S
DESIGNED TO BE DISTRIBUTED.
IT'S AN IMPLEMENTATION OF A SYSTEM DESCRIBED IN
THE CHUBBY PAPER BY GOOGLE.
THE MAIN DIFFERENCE IS ETCD USES A CONSENSUS
ALGORITHM CALLED RAFT.
IT'S EASIER TO IMPLEMENT, HAS IDENTICAL FAULT
TOLERANCE AND PERFORMANCE CHARACTERISTICS.
IN ENGLISH, THAT MEANS THAT YOU CAN TAKE THIS
SYSTEM AND FOR DEVELOPMENT AND TESTING, IT'S
FINE, YOU CAN DO THIS, RUN IT ON THE SAME THING
BUT IF YOU'RE GOING TO PRODUCTION AND WANT TO
KEEP THE STUFF ONLINE FOR REAL, YOU CAN SET UP A
CLUSTER OF ETCD NODES.
WE HAVE FOUR MORE SERVERS.
>> GENERALLY YOU WANT TO KEEP THE CLOSE TIER A
STATIC SIZE, LIKE THREE TO FIVE SHOULD BE FINE
AND THE NICE THING ABOUT THAT IS BECAUSE OF THE
CONSENSUS ALGORITHM, BECAUSE THE MAJORITY OF THE
NODES ARE ONLINE AND CAN SEE EACH OTHER, THE
CLUSTER WILL KEEP WORKING.
SO WITH FIVE NODES, TWO WILL FAIL AND THE CLUSTER
WILL WORK AS IF NOTHING HAD HAPPENED.
AND THIS SORT OF ARCHITECTURE CAN SUPPORT TENS,
HUNDREDS, THOUSANDS OF WORKER SERVERS, SO THIS IS
WHAT YOU WOULD WANT TO GO TO PRODUCTION WITH IF
YOU HAD, SAY, A BUNCH OF ETCD SPOT INSTANCES, YOU
WOULD HAVE THOSE ON ONE SIDES AND THE MORE
PERSISTENT SET OF THE NODES TO HELP COORDINATE
THE CLUSTER.
EVERYONE FOLLOW?
CLUSTERS, YEAH, DISTRIBUTE SYSTEMS, EVERYTHING
BREAKS IN INTERESTING WAYS.
FOR THESE DEMOS, I'M GOING TO SET UP A 3-NODE
CLUSTER USING A VOLUME VIRTUAL MACHINE.
I'M RUNNING ETCD AND APPS ON THE SAME NODES.
YOU COULD THEORETICALLY GO TO PRODUCTION WITH
THIS BUT YOU DON'T WANT TO BECAUSE YOU CAN'T IN
THIS SORT OF SYSTEM EASILY DROP AND AND OTHER
WORKER NODES, RIGHT?
IT'S MUCH BETTER TO KEEP THOSE SEPARATE, BUT FOR
DEMONSTRATION, WE'RE GOOD TO GO.
THE NICE THING ABOUT ETCD, WHILE IT'S BUNDLED
WITH COREOS, IT'S INDEPENDENTLY -- IT'S BEEN
ADOPTED BY THE GOOGLE SCHEDULES, BY VULCAN D
PROXY AND SEEING ACTUAL COLLABORATION AND REUSE.
COOL TECHNOLOGY, RIGHT?
BUT WE HAVEN'T TALKED ABOUT HOW WE'RE GOING TO
RUN OUR APPS ON THIS THING, JUST TALKED ABOUT HOW
WE'RE GOING TO STOP THE SERVERS FROM REBOOTING AT
THE SAME TIME WHICH IS AN IMPORTANT PROBLEM, BUT
THAT DOESN'T ACTUALLY MAKE US ANY MONEY OR LET US
SHOW OFF OUR SIDE PROJECT OR ANYTHING LIKE THAT.
THE REASON THAT COREOS IS ABLE TO DO FULL SYSTEM
STYLE UPDATES IS THAT THEY MAKE THE OPERATING
SYSTEM EXTREMELY BARE BONES SO THE WHOLE ISO IS
140 MEGABYTES.
WHICH MEANS THERE'S NO ROOM FOR PYTHON, PERL,
RUBY, JAVASCRIPT.
THE BASE SYSTEM IS NOW AT READ-ONLY SO YOU CAN'T
EVEN MUCK WITH THINGS LIKE USER BEN.
SO WHAT DO YOU DO, HOW DO YOU RUN ANYTHING?
USE CONTAINERS.
SO CONTAINERS AT A VERY HIGH LEVEL ARE SOMEWHERE
BETWEEN A REALLY LIGHTWEIGHT VIRTUAL MACHINE OR A
REALLY HEAVY WEIGHT CHROOT.
THE IDEA IS THAT INSTEAD OF A VIRTUAL MACHINE
WHERE YOU COME TO A HOST AND SAY HERE IS AN
ENTIRE SOFTWARE-BASED DEFINITION OF A WHOLE
COMPUTER THAT I WANT YOU TO EMULATE, WITH A
CONTAINER, DESIRING HERE IS A FILE SYSTEM, RUN
THAT PROGRAM AND KEEP IT ISOLATED FROM OTHER
THINGS.
THANKS.
AND YOU'RE TRUSTING THE HOST SYSTEM TO PROVIDE
THE ISOLATION, TO PROVIDE THE KERNEL AND YOU GET
THE ACCOUNTING AND THE MANAGEMENT SOMETIME OF A
VIRTUAL MACHINE BUT YOU GET MUCH BETTER DENSITY,
MUCH BETTER PERFORMANCE BECAUSE EVERY CONTAINER
ON THAT HOST IS SHARING THE SAME KERNEL.
IT'S -- IT'S MUCH MORE LIKE LAUNCHING A LOCAL
PROCESS THAN EMULATING AND BOOTING A WHOLE
MACHINE.
AND THIS HAS A LOT OF BENEFITS.
DOCKER KINDS OF POPULARIZED THIS IN THE LIE NICKS
WORLD BUT THIS IDEA HAS BEEN AROUND FOR A LONG
TIME.
FREEBIE S DHAD JAILS BACK IN 1999, WHICH IS THE
SAME THING.
WE'RE ONLY SEEING THE BUZZ NOW BECAUSE LINUS
ADDED A FEATURE CALLED SEA GROUPS TO GIVE SIMILAR
ISOLATION, AND ONLY TWO YEARS SINCE DOCKER SHOWED
UP AND SAID WE HAVE THIS CAPABILITY, WE SHOULD
WRAP IT UP IN A HIGH LEVEL INTERTASTE MAKES IT
USABLE AND FIND A SERIALIZATION FORMAT THAT WE
CAN ACTUALLY BUILD AN IMAGE HERE AND SHARE IT
SOMEWHERE ELSE.
COREOS SHIPS TWO CONTAINERS RUN TIMES, YOU HAVE
DOCKER AND ONE OF THEIR OWN DESIGN CALLED ROCKET,
THAT'S DESIGNED TO BE MORE MINIMAL.
THEY'VE TRIED TO USE ROCKET TO NARROW IN ON A DEV
SPACE, AN INTEROPERABLE SPECIFICATION FOR
CERTAINLYIZING CONTAINERS.
DOCKER IS MORE INTERESTED IN WE HAVE A WORKING
IMPLEMENTATION SUPPLY SOURCE, LET'S GO FROM
THERE.
IT GETS DRAMATIC AND POLITICAL.
THEY BOTH DO THE SAME THING, EFFECTIVELY.
SO HOW DOES THIS ACTUALLY WORK IN PRACTICE?
LET'S COME OVER HERE.
WOW, THAT WAS A COOL SOUND.
THAT WASN'T ME, WAS IT?
ALL RIGHT, SO I'M SHELLED INTO ONE OF MY CORE
MACHINES AND I'VE GOT A REALLY BASIC PYRAMID
APPLICATION.
SO THERE'S MY HELLO WORLD, DON'T READ IT, IT'S
UGLY, FROM THERE, FROM THE TUTORIAL, I DON'T KNOW
QUITE ALL THAT MUCH ABOUT PYRAMID THOUGH IT'S
LOOKING NICE.
I'VE GOT MY REQUIREMENT ON TCP WHICH SAYS IT
EQUALS 514, AND THEN I'VE GOT A DOCKER FILE
THAT'S BASIC, SAYS FROM PYTHON 343 ON BUILD AND
COMMAND IS PYTHON 3 HELLO.PI.
SO WHAT DOCKER LETS YOU DO IS LETS YOU CREATE
THIS HIERARCHY OF SYSTEM IMAGES.
IF WE LOOK AT DOCKER IMAGES TREE, SO WE CAN SEE
THAT THERE IS THIS IMAGE AT THE TOP AND A DESCEND
NOT FROM IT IS THIS PYTHON ON BUILD IMAGE AND
THEN THERE'S MY APP AT THE BOTTOM THAT HE BUILT
BEFOREHAND IN CASE THE NETWORK WENT DOWN.
SO WHAT THIS ON BUILD IMAGE IS, IT EMULATES A
HEROKU BUILD PACK, SO WHEN I TRY TO BUILD THIS,
I'M GOING TO RUN INSTALL ON ITS, COPY IT IS
SOURCE CODE INTO USER SOURCE APP AND THE IMAGE IS
BUILT.
NOW WE CAN SAY, DOCKER RUNNING, AND WE'LL MAP
PORT 8020 PORT 8080 IN THE CONTAINER AND RUNNING
THE CONTAINER IN MY APP.
IS THERE WE GO.
SO NOW IF I COME BACK OFF HERE, BAM, HELLO WORLD.
I HAVE I'VE GOT AN APP RUNNING CONTAINER, HELLO,
PYCON.
LIKE THERE'S REAL SOFTWARE RUNNING IN A CONTAINER
RIGHT NOW AND THAT'S NOT SUPER IMPRESSIVE, EVEN
THOUGH YOU CLAPPED SO YOU'RE VERY NICE.
INSTEAD OF RUNNING THAT COMMAND, LET'S RUN BASH.
OH, EXIT -- LOOK HOW FAST I CAN START AND STOP
CONTAINERS, CAN'T DO THAT WITH A VM.
EVERY TIME I INVOKE THAT COMMAND, BASH WAS
CREATED INSIDE A COPY -- A FILE SYSTEM SNAPSHOT
FROM THIS CONTAINER, HAD ISOLATION FROM OTHER
THINGS IN THE PROCESS, OR IN THE OPERATING
SYSTEM, JUST LIKE YOU WOULD EXPECT WITH A VIRTUAL
MACHINE.
BUT WAY LIGHTER WEIGHT.
SO IF I LOOK AROUND IN HERE, THERE'S MY APP, THIS
LOOKS LIKE A -- AN INSTALL, GOT AN APP KIT, GOT
AN ETCD DEBIAN SYSTEM, AND I LOOK LIKE I'M IN A
DEBIAN SYSTEM EVEN THOUGH I'M ON A COREOS SYSTEM.
THIS IS A HUGE BENEFIT FOR CONTAINERS, YOU CAN
DEVELOP A CONTAINER LOCALLY AND THEN DEPLOY THAT
ON FEDORA OR RED HAT AND DOESN'T MATTER, AS LONG
AS YOU'RE USING MODERN LINUX AND HOSTING ON
MODERN LINUX, IT WILL JUST RUN, WHICH IS REALLY
FANTASTIC.
WE HAVEN'T TALKED ABOUT -- I'M GOING IN AND
MANUALLY RUNNING THINGS, THAT DOESN'T SCALE.
WE WANT TO GET TO THE NICE DECLARATIVE PLACE
WHERE WE CAN SEE KEEP TWO RUNNING BUT NOT ON THE
SAME MACHINE AND THAT REQUIRES SOMETHING AKIN TO
A CLUSTER LEVEL NET SYSTEM.
IF WE'RE DEALING WITH A SINGLE SERVER, WE HAVE
THINGS TO USE.
BUT WE'RE NOT DEALING WITH A SINGLE SYSTEM
ANYMORE.
SO THERE ARE TWO SCHEDULERS THAT WORK REALLY WELL
WITH COREOS, GETS BOUNDS HE WOULD WITH ONE CALLED
FLEET THAT'S BASIC AND ONE CALLED CUBER.NETS,
BY -- THAT'S SUPER COMPLEX, IF YOU GOT MILLIONS
OF SERVERS AND YOU'RE TRYING TO EEK OUT EVERY
PERCENT OF EFFICIENCY, YOU WANT KUBERNETES.
THE...
[ Audio Indiscernible ]
COREOS IS COMMERCIAL OFFERING, TECTONIC USES
KUBERNETES, BUT, AGAIN, YOU KNOW, AND BOTH OF
THESE ARE BUILT ON ETCD.
SO ANOTHER PATTERN, LIKE IT'S NOT NECESSARILY
SCHEDULING OR ANY OTHER THING THAT GIVES US HIGH
AVAILABILITY, ALL THIS COMES DOWN TO IS HAVING
CONSENSUS ON THE NETWORK, HAVING THAT ONE PLACE
ETCD WHERE WE CAN AGREE ON WHAT THE STATE OF ALL
THE MACHINES ARE.
SO FLEET, FLEET'S SIMPLE.
A CLUSTER INTERFACE FOR SYSTEM C.D.
IF YOU HAVE -- YOU PROBABLY DON'T LIKE IT.
UNFORTUNATELY, EVERY MAJOR DISTRIBUTION KIND OF
SEEMS TO LIKE IT.
AND SO WHAT SYSTEMD DOES IS LET YOU WRITE WITHIN
ITS FILES THAT LOOK LIKE THIS, WHERE YOU SEE
HERE'S MY APP, IT REQUIRES DOCKER, BEFORE IT
STARTS, GO TRY TO KILL ANY OTHER VERSIONS OF IT
AND REMOVE THEM.
WHEN IT STARTS, GO AND RUN THIS THING.
JUST LIKE YOU SAW ME RUN ON THE COMMAND LINE,
DOCKER RUN, AND USE DOCKER STOP TO KILL IT.
EVERYTHING UP HERE IS A NORMAL SYSTEM FILE.
WHAT FLEET ADDS IS THIS LITTLE X FLEET SECTION AT
THE BOTTOM, WHICH CAN HAVE THINGS LIKE CONFLICTS
MY APP, AT STARS, DOT SERVICE.
THIS IS THE THING THAT TELLS FLEET NOT TO PUT TWO
OF THESE ON THE SAME MACHINE.
AND YOU HAVE OTHER CONSTRAINTS AVAILABLE, TOO.
YOU CAN SAY PUT THIS ON A SPECIFIC MACHINE
RUNNING ANOTHER CONTAINER OR PUT IT ON A SPECIFIC
MACHINE BY I.D., OR BASED ON META DATA.
YOU CAN SAY, MAKE THIS GLOBAL, RUN IT ON EVERY
MACHINE THAT'S AVAILABLE.
SO WE HAVE ALL THAT.
LET'S LOOK WHAT IT LOOKS LIKE IN PRACTICE.
SO I HAVE THIS SERVICE FILE.
IT'S JUST WHAT YOU SAW BEFORE.
AND I'M GOING TO INSPECT MY FLEET CLUSTER, SO
LET'S LIST MACHINES.
SO I'VE GOT THREE SERVERS.
LIST UNITS.
THERE IS NOTHING RUNNING ON THEM RIGHT NOW.
SO LET'S TAKE THIS UNIT FILE AND SAY, FLEET
CONTROL SUBMIT, MY APP SERVICE.
THE @ SYMBOL IS A TEMPLATE, SO, SAYS, HEY,
REPLACE LIKE THIS I WITH THE NUMBER OF THE THING
YOU'RE RUNNING.
SO IF WE START ONE, IT WILL BE ONE, IF WE START
ANOTHER ONE, THAT WILL BE 2.
SO WHAT SUBMIT DOES IS IT TAKES THAT FILE AND
STORES IT IN THE ETCD CLUSTER.
ETCD CONTROL LS CURSIVE, COREOS.COM.
SO, LET'S SEE.
THAT LOOKS LIKE IT.
SO IF WE SAY ETCD CONTROL, GET THAT, BAM, THERE
IS OUR UNIT FILE.
IT'S GOT A HASH WHICH POINT TO THIS.
AND THERE IT IS.
YOU ALSO SEE FLEET KEEP TRACK OF THE VARIOUS
MACHINES AVAILABLE.
BUT WE'RE NOT ACTUALLY RUNNING THIS YET, JUST
MADE IT AVAILABLE TO THE CLUSTER.
SO I CAN LIST UNIT FILES AND WE CAN SEE THAT IT'S
THERE BUT NOT ACTIVE.
LET'S BOOT ONE OF THESE UP.
THERE WE GO.
LET'S START ANOTHER ONE.
SO THIS LAUNCHED ON THE MUCH ENDING IN .101, THE
SECONDS ONE WILL LAUNCH ON -- OH, WAIT FOR IT.
ONE OR TWO.
THAT'S COINCIDENCE, COULD HAVE ENDED UP ON THREE.
BUT IF WE LOOK AT FLEET CONTROL, LIST MACHINES,
WE CAN SEE THOSE MACHINES, LIST UNITS.
WE CAN SEE THOSE APPS RUNNING ON THOSE VARIOUS
MACHINES.
AND WE CAN USE NORMAL SYSTEM D COMMANDS SO SAY
JOURNAL, STATUS, RATHER, LET'S DO STATUS.
MY APP AT 1.
SO YOU CAN SEE THAT THAT ARM IN THE -- FAILED
BECAUSE THERE WASN'T PREEXISTING IMAGE BUT THE
MAIN PROCESS IS ACTIVE AND RUNNING, AND HERE IS
THE LAST BIT OF OUTPUT FROM RUNNING THAT.
SO I CAN SEE THAT FOR ANYTHING RUNNING, EVEN
THOUGH I'M ON SYSTEM -- ON THE CORE 1, I CAN LOOK
AT THAT ON 2, AND I CAN ACTUALLY SAY, FLEET
CONTROL SSH, AND JUMP OVER TO THE BOX THAT'S
RUNNING MY TASK VERY EASY WITHOUT HAVING TO KIND
OF DE-REFERENCE IT.
SO THAT'S HOW WE GO FROM A UNIT FILE TO HAVING
TWO THINGS RUNNING.
I PROMISED YOU HIGH AVAILABILITY, SO LET'S GO
KILL ONE OF THESE.
SO LET'S SAY -- THIS IS WAY SMALL, MAKE THAT BIG.
PROJECTS, PYCON...
SO WE'LL SHELL INTO COREO2.
OOPS.
SSH COREO2.
THERE WE GO.
SO WE'RE IN THIS MACHINE THAT'S RUNNING MY APP 2,
RIGHT?
SO LET'S SHUT DOWN EACH NOW.
OH, PSEUDO SHUT DOWN.
AND SO BAM.
IT'S GONE AND UP ON THREE.
[ Applause ]
SO WE CAN REBOOT THAT MACHINE AND IF YOU WERE
DOING THIS WITH A NORMAL SCHEDULER, WHEN THIS
MACHINE COMES BACK UP, IT'S GOING TO, YOU KNOW,
TRY TO RESTART THAT FILE, NOT SO BECAUSE IN THIS
CASE BECAUSE FLEET'S THE THING THAT'S CONTROLLING
WHAT HAPPENS.
IT'S LIKE, WAIT, I ALREADY FILLED THIS, I'M
RUNNING ON TWO SERVERS ALREADY, 102 DOESN'T NEED
TO RESTART IT SO WHEN THIS COMES BACK UP, WE CAN
SAY THIS MACHINE'S GOT THE THREE MACHINES AGAIN,
BUT THAT'S STILL JUST RUNNING ON MACHINE 1 AND 3.
KIND OF COOL, RIGHT?
AT THIS POINT YOU'VE STILL GOT TO FIGURE OUT, ALL
RIGHT, I HAVE MY STUFF, IT CAN SURVIVE.
LET'S KILL ANOTHER -- I CAN SURVIVE WHILE THE
MACHINE IS GETTING THE PLUGGED PULLED ON IT.
BUT THAT MEANS YOU HAVE TO DESIGN YOUR APPS
DIFFERENTLY.
IF A MACHINE CAN GO AWAY, IF A CONTAINER CAN BE
KILLED ON A MACHINE, THEN SHOW UP ON A DIFFERENT
MACHINE, YOU HAVE TO MINIMIZE STATE.
BECAUSE YOU'RE NOT GOING TO HAVE THE SAME HARD
DRIVE AVAILABLE TO YOU.
HEROKU WROTE A REALLY NICE DOCUMENT CALLED "THE
12 FACTOR APP DESIGN PRINCIPLES," REALLY WORST
READING THAT.
TALKS ABOUT HOW THEY'VE COME TO BUILD APPS THAT
WORK WELL ON THE HEROKU PLATFORM WHICH HAS MANY
OF THE SIMILAR DESIGN CONSTRAINTS.
BUT THIS DOESN'T SOLVE THINGS THAT ACTUALLY NEED
STATE, LIKE DATABASES AND LOAD BALANCES, RIGHT,
BECAUSE I WILL I'M OVER HERE, GOT THIS THING
RUNNING ON 101 AND 103, YOU KNOW, THERE IT IS ON
101, THERE IT IS ON 103.
BUT IT WAS ON 102 AND THAT'S TOTALLY DEAD NOW,
RIGHT?
SO YOU STILL NEED TO HAVE SOMETHING IN FRONT OF
THIS DOING LOAD BALANCING.
AND THAT'S OKAY.
THERE'S NOT A GREAT STORY FOR STAPLENESS IN THIS
SORT OF AN ARCHITECTURE YET.
BUT YOU DON'T TO HAVE RUN YOUR WHOLE ENVIRONMENT
ON COREOS TO REAP THE BENEFITS OF RUNNING A LOT
OF WORKER PROCESSES ON IT.
IN SOME CASES, IF YOU'RE ON LIKE AMAZON ECTUBE,
YOU CAN OUT-SOURCE THIS, PAY MONEY TO START UP AN
RDS OR SOMETHING, BUT BEING ALSO FOR WEEKEND
PROJECTS, FINE, GO BIND YOUR DATABASE, SAY ONLY
RUN THIS ON MACHINE I.D.XAND IT REBOOTS, NO BIG
DEAL, RIGHT?
IT WILL BE OUT FOR A COUPLE OF MINUTES EVERY
COUPLE WEEKS, YOU'RE STILL GOING TO BE OKAY AND
IT DOES GET YOU TO A BETTER PLACE THAN YOU WERE
BEFOREHAND FOR THE STATEFUL PARTS BUT DOES GET
YOU TO A MUCH BETTER PLACE FOR THE THINGS THAT
AREN'T NECESSARILY STATEFUL, RIGHT?
IF YOU HAVE IDEAS FOR MAKING THIS BETTER, THINGS
LIKE POSTGRES, IS NOT CLUSTER AWARE, SO IF YOU
NEED POSTGRES, YOU NEED TO BABYSIT IT, STILL.
GREAT ROOM FOR INNOVATION.
BUT THE END OF THIS, LIKE, WE'VE DONE IT, RIGHT?
WE HAVE A PLATFORM THAT'S SELF UPDATING AND SELF
ORGANIZING AND SELF HEALING AND WE DID IT BY
USING AN OPERATING SYSTEM THAT AUTOMATICALLY
UPDATES, USING AUTONOMIC UPDATES.
WE PUT THEM IN THE ISOLATED CONTAINERS.
DON'T REDISTRIBUTE TO -- OH, MAN -- THERE WE GO.
WEB TECHNOLOGY, MAN.
SO WE ALSO SET UP MULTIPLE CONTAINERS, MULTIPLE
SERVERS IN A COORDINATE CLUSTER USING ETCD, AND
WE USED A SCHEDULER FLEET TO DISTRIBUTE JOBS
ACROSS THE CLUSTER.
NOW YOUR TURN TO PLAY WITH THIS, RIGHT?
I'VE SHOWN YOU IT'S POSSIBLE, I'VE SHOWN YOU WHAT
DESIGNS CHANGE, LIKE THINGS HAVE TO BE ABLE TO
DIE AND COME BACK UP ON A DIFFERENT HOST.
YOUR TURN TO PLAY WITH IT.
COREOS IS RUN ON A TON OF PLATFORMS.
I DID EVERYTHING ON A LOCAL TRIO VIRTUAL MACHINE
RUNNING VAGRANT.
YOU COULD ALSO DO THIS ON AZURE, ECTUBE,
RACKSPACE, ALL THESE HAVE OFFICIAL COREOS IMAGES
AND DIGITALOCEAN ALSO SUPPORTS IT.
A FRIEND OF MINE STARTED WORKING AT DIGITALOCEAN,
SHE TOLD ME TO USE THE CODE SAMMY LOVES PYCON TO
GET A $40 CREDIT, SO YOU CAN SPIN UP THREE VMs
FOR TWO AND A HALF MONTHS PLAY WITH THIS.
FEEL FREE TO GIVE IT OUT TO PEOPLE, SUPER GREAT.
BUT I'VE BEEN TALKING FOR A WHILE.
LET'S TAKE SOME QUESTIONS.
YOU CAN FIND MY SLIDES, CHECK OUT DIGITALOCEAN,
USE THE CODE, FREE STUFF.
MIC IS IN THE BACK.
THANK YOU SO MUCH.
[ Applause ]
>> I WONDER IF YOU COULD SAY WHAT THE EXPERIENCE
IS LIKE RUNNING COREOS ON A MAC DEVELOPMENT
ENVIRONMENT, DOES IT SUCK?
>> IT KIND OF SUCKS.
SO THE...
[ Laughter ]
ONE OF THE PREMISES IS THAT YOU'RE GOING TO SHARE
YOUR KERNEL BETWEEN ALL YOUR CONTAINERS AND IF
I'M USING A MAC AND TRYING TO RUN THINGS ON
LINUX, THAT WON'T WORK, SO YOU STILL NEED A
VIRTUALIZATION LAYER.
NOT IDEAL.
IT'S TOTALLY FINE FOR TESTING, THERE IS A VAGRANT
COREOS RECIPE THAT MAKES IT DEAD SIMPLE TO SPIN
UP THREE OF THESE THINGS, PLAY WITH THEM.
BUT YOU'RE STILL BOOTING A VM TO THEN GO RUN
OTHER VMs BECAUSE YOU CAN'T DO THIS NATIVELY ON
YOUR DESK TOP.
IF YOU'RE RUNNING -- AND RUNNING LINUX, WAY AHEAD
OF THE GAME.
IT IS WHAT IT IS.
WE'RE DEPLOYING LINUX, YOU HAVE TO DEAL WITH IT
SOMEWHERE.
>> AUDIENCE:  AND GIVING IT AN ENORMOUS AMOUNT OF
RAM.
YOU GIVE THE VAGRANT CONTAINER AN ENORMOUS AMOUNT
OF RAM AND WALK AWAY.
>> COREOS DOESN'T TAKE A SUPER AMOUNT OF RAM,
BOOTS REALLY QUICK BUT YOU HAVE TO BE RUNNING THE
CONTAINERS ON LINUX.
THERE ARE OBVIOUSLY LIKE MICROSOFT JUST ANNOUNCED
A CONTAINERIZATION SOLUTION FOR WINDOWS EARLIER
THIS WEEK.
BUT CONTAINERS AREN'T PORTABLE ACROSS OPERATING
SYSTEMS.
THEY'RE PORTABLE ACROSS DISTRIBUTIONS, SO, LIKE,
A CONTAINER THAT HAS A USER LAND FROM RED HAT
WILL RUN ON A HOST USING UBUNTU OR ARGENTE, BUT
YOU CAN'T TAKE THAT CONTAINER LIKE YOU COULD WITH
A VM AND RUN IT ON WINDOWS.
>> AUDIENCE:  HEY, DAN, GREAT TALK.
QUICK QUESTION.
IF YOU HAVE A SERVICE THAT DEPENDS ON HAVING
SOMETHING ON DISK PERSISTENTLY AND YOU WANT TO BE
ABLE TO START THIS SERVICE ON ANY SORT OF
ARBITRARY NODE, HOW ARE YOU GOING TO CREATE A
FILE SYSTEM WHICH, SAY, IS SHARED ACROSS THOSE
INSTANCES THAT THIS SERVICE WILL HAVE ACCESS TO?
>> THERE'S NOT AN ANSWER FOR THAT BAKED IN.
IF YOU'RE USING EC2, YOU CAN GO IN AND USE, LIKE,
ELASTIC BLOCK STORES, NOW AN NFS CLIENT FILE
SERVICE OR SOMETHING.
SO YOU WOULD WANT TO JUST DO A NORMAL KIND OF
NETWORK FILE SHARE OR A NETWORK BLOCK MOUNT AND
MANAGE THAT OUTSIDE OF THIS.
>> AUDIENCE: COOL, THANKS.
>> AUDIENCE:  GREAT TALK.
QUICKLY FOR THE GUY IN THE BLUE FIREFOX T-SHIRT,
THERE'S BOOT TO DOCKER, THAT GETS YOU A SLIMMED
DOWN VM THAT RUN ON OSX WHICH IS PRETTY GOOD, IF
YOU WANT TO PLAY AROUND WITH DOCKER THINGS.
BOOT TO DOCKER.
MY QUESTION IS AROUND FLEET VERSUS KUBERNETES, I
KNOW THERE IS A LOT OF WORK THAT YOU'RE DOING ON
THEM, I'M WONDERING WHAT THE FUTURE PATH IS.
SEEMS LIKE KUBERNETES IS DOING THINGS THAT FLEET
IS DOING.
IS THERE A DIFFERENCE, ARE YOU MOVING TOWARDS
KUBERNETES OR WHAT'S THE --
>> SO ONE POINT OF CLARIFICATION, I'M NOT THOSE
GUYS.
I WORK FOR MOZILLA, JUST A HOBBYIST IN THIS SPACE
BUT I DID TALK TO KELSEY HIGHTOWER WHO WORKS FOR
COREOS BEFORE I GAVE THIS TALK AND THE SENSE I
GOT FROM HIM WAS THAT FLEET IS AN EXCELLENT BASIC
SCHEDULER AND IF YOU NEED CAN YOU BEER NETS YOU
KNOW IT.
YOU GET 5% BETTER ALLOCATION OF YOUR RESOURCES,
YOU SAVE MILLIONS OF DOLLARS IN THE POWER BILL,
THAT'S WHEN YOU MOVE TO KUBERNETES, BUT FLEET
ITSELF IS A GREAT PRIMITIVE.
SO YOU COULD USE THAT TO BOOT STRAP THE
KUBERNETES ON THE CLIENTS' NETWORK.
KUBERNETE MOMENTUM, GOOGLE HAS TONS OF ENGINEERS
ON IT ALL THE TIME BUT SEEMED TO BE GEARED
TOWARDS LARGER SCALE DEPLOYMENT.
>> AUDIENCE:  SO YOU CAN SEE -- NOT YOU BUT THE
GENERAL, FLEET AND KUBERNETES EXISTING SIDE BY
SIDE, BASICALLY.
>> ABSOLUTELY.
>> AUDIENCE:  THIS IS A BRIEF FOLLOW-UP ON AN
EARLIER QUESTION.
HAVE YOU EXPERIMENTED WITH AMAZON'S ELASTIC BLOCK
STORE AS A MEANS OF PERSISTENCE WITH A DATABASE
SERVER LIKE POSTGRES OR ANYTHING ELSE?
FEEL THAT'S READY FOR PRODUCTION YET OR IT MIGHT
WORK IF YOU TRY IT SORT OF THING?
>> IT'S MORE OF A -- IT SHOULD WORK WITHIN THE
CONSTRAINTS OF EBS.
BUT THE THINGS I'M DOING, I'M WORKING ON HOBBY
PROJECTS.
THIS STUFF, EVERYTHING I SHOWED YOU WILL SCALE TO
HUNDREDS OR THOUSANDS OF SERVERS.
I'M CARING MORE ABOUT, LIKE, THREE, BECAUSE I
DON'T WANT TO DEAL WITH THAT ONE EMAIL ONCE A
MONTH WHERE IT'S HEY, THERE IS A HARDWARE PROBLEM
ON YOUR SERVER.
WE'VE REBOOTED, MAN, MY STUFF WAS OFFLINE, SO I'M
TRYING TO FIX THAT ON A LOW LEVEL AND I FIND IT
INTERESTING THIS SORT OF TECHNOLOGY DOES SCALE
DOWN TO THAT PRETTY WELL BUT PUTTING MY STAPLE
STUFF IN RDS ON AMAZON.
>> AUDIENCE:  OKAY, THANKS.
>> AUDIENCE:  WHAT YOU'VE BEEN PROVIDING IS
REALLY INTERESTING AND I WOULD LIKE TO KNOW HOW
THIS IS FITTING -- CONFIGURATION MANAGEMENT TOOL
SUCH AS SALT AND PEPPER, WHERE SOME COMPANION
MIGHT HAVE INVESTED IN MANIFEST OR STATES AND HOW
DO YOU SEE THE TRANSITION BECAUSE, LIKE, THE
TRANSITION BETWEEN SOMETHING WHICH IS DECLARATIVE
AND WHERE YOU HAVE ALL YOUR CONFIGURATION,
GETTING SOMETHING TO SUCH VOLATILE THING.
>> RIGHT, SO IT SEEMS LIKE THE COREOS PLATFORM
ITSELF, YOUR SYSTEM IS MOUNTED IS READ ONLY.
YOU CAN'T REALLY CHANGE THE CONFIGURATION.
I MEAN, YOU CAN OBVIOUSLY ADD THINGS TO SLASH ETC
AND THAT, BUT IN A CERTAIN WAY OBVIATES THE NEEDS
FOR TOOLS LIKE CHEF, PUPPET, SALT STACK, ANSIBLE,
BECAUSE YOU'RE NOT TRYING TO MAKE THE MACHINES.
YOU'RE STILL TRYING TO BUILD A CONTAINER BUT THE
TOOLS THAT EXIST FOR THAT, THE DOCKER FILES THAT
SAY, GO DOWN THIS, RUN THIS, DO THAT, KIND OF
TAKE CARE OF THAT AND ONCE YOU'RE DONE, THAT
SINGLE CONTAINER IS PORTABLE.
YOU CAN SERIALIZE IT, SCP IT FROM ONE HOST TO
ANOTHER, AND PICKS UP AND RUNS WITHOUT HAVING TO
HAVE LIKE THE LONG-LIVED CONFIGURATION MANAGEMENT
OR THE CONFIGURATION CONVERGENCE, THINGS YOU
USUALLY GET WITH THOSE SORTS OF TOOLS.
SO MIGHT GET RID OF THEM WHICH IS KIND OF
TERRIBLE BUT GETTING RID OF STUFF IS ALSO KIND OF
GOOD.
>> AUDIENCE: SO IF YOU HAVE, LIKE, A THOUSAND
APPLICATION SERVERS AND, YOU KNOW, THEN FIVE ETCD
NODES, DOESN'T SEEM LIKE A BIG DEAL BUT IF YOUR
SCALE IS THREE APP SERVERS AND YOU NEED A NODE OF
3 TO FIVE ETCD THINGS, DOESN'T SEEM TO MAKE
SENSE.
SO IF YOU'RE IN PRODUCT BUT WITH A LOW NUMBER,
DOES THAT -- IS THAT HOW THEY USE IT THERE?
>> YEAH, THIS TOTALLY MAKES SENSE.
YOU GET ALL THE REDUNDANCY -- THIS IS A
PRODUCTION-READY DEPLOYMENT, JUST WITH THREE
NODES.
THE PROBLEM THERE IS IF ONE OF THOSE MACHINES
DIES, LIKE IF YOU'RE USING ETCD SPOT INSTANCES OR
SOMETHING, YOU HAVE TO TAKE CARE TO INFORM ALL
THE OTHER NODES THAT THIS ONE IS NO LONGER
SOMETHING THEY SHOULD BE LOOKING FOR BECAUSE IF
SOMETHING ELSE SHOWS UP, THEN YOU HAVE A REALLY
WEIRD SYSTEM IN THE PART THAT DOES CONSENSUS,
RIGHT, BECAUSE IT'S LIKE, I HAVE FOUR THINGS, I
THOUGHT I HAD THREE THINGS.
I THINK IT'S WEIRD.
BUT IF YOU'RE JUST STANDING UP A COUPLE OF
LONG-RUNNING VMs TO A FIXED NUMBER THAT,
CONFIGURATION WORKS GREAT.
TRADITIONALLY, YOU DON'T WANT TO TURN ON ALL THAT
MANY ETCD NODES, STARTS DEGRADING AFTER NINE.
I THINK IN THE GOOGLE CHUBBY PAPER, THEY HAD 5
MACHINES HANDLING HUNDREDS OF CONCURRENT CLIENTS.
SO SOMETHING LIKE THAT REALLY DOES SCALE
ENORMOUSLY, SOMETHING LIKE THAT IS FINE IF YOU'RE
USED TO A TRADITIONAL LONG-RUNNING VM.
TIME FOR ONE MORE?
>> AUDIENCE:  SO YOU MADE A COMMENT AND I'VE
HEARD IT A NUMBER OF TIMES THAT THIS
AUTOMATICALLY UPDATED AND SAVED YOU FROM A NUMBER
OF SECURITY PROBLEMS.
BUT IT DIDN'T.
>> YES, I THINK I KNOW WHERE YOU'RE GOING AND
THIS IS GREAT.
THANK YOU.
>> AUDIENCE:  BECAUSE YOUR USER LANDS IS WHERE
LIB SSL LIVED AND NONE OF YOUR LIB SSLs ON YOUR
CLUSTER GOT UPDATED WHEN EVERYTHING REBOOTED.
>> SPOT ON.
SO THIS WOULD HELP YOU WITH THINGS LIKE KERNEL
LEVEL VULNERABILITIES BUT YOU STILL HAVE TO
MAINTAIN YOUR USER LANDS AND SO WHAT YOU WANT TO
DO IS END UP MAKING SURE THAT YOU'RE REBUILDING
YOUR DOCKER IMAGES REGULARLY, REDEPLOYING THEM
AND THINGS LIKE THAT ONCE THINGS COME OUT.
THE NICE THING, THIS GETS YOU AWAY FROM HAVING TO
MANAGE BOTH THE HOST SYSTEM AND THE APPLICATION
SYSTEM WITH A LOT OF CARE, RIGHT?
LIKE RED HAT WILL SELL YOU A TEN-YEAR
SUBSCRIPTION SO YOU DON'T HAVE TO UPDATE AND
THAT'S SCARY.
THIS LETS YOU WORRY, HERE'S MY APPLICATION, I CAN
UPDATE IT ON MY OWN AND NOT WORRY ABOUT THE
EFFECT.
>> THAT'S ALL THE TIME WE HAVE FOR QUESTIONS.
THANK YOU SO MUCH, DAN.
>> THANK YOU.
03:36:44