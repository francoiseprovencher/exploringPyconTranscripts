>> ALL RIGHT.
HELLO, EVERYBODY.
I HAVE QUITE AN HONOR TODAY.
I AM LUCKY ENOUGH TO INTRODUCE BRANDON RHODES, A
LONG-TIME PYTHON DEVELOPER, MAINTAINER OF SEVERAL
AMATEUR ASTRONOMY LIBRARIES AND A DEVELOPER FOR
DROPBOX.
HE'S ALSO A QUIZ MASTER EXTRAORDINAIRE, AS SOME
PEOPLE GOT TO FIND OUT LAST NIGHT.
TODAY HE WILL BE PRESENTING ON OH, COME ON, WHO
NEEDS BYTEARRAYS.
WITHOUT FURTHER ADO, BRANDON RHODES.
[ Applause ]
>> WELCOME, EVERYBODY.
I HOPE YOU'RE HAVING A GOOD TIME AT PYCON AND IN
MONTREAL.
MY TOPIC TODAY IS INDEED BYTEARRAYS.
A VERY INTERESTING REASONED EDITION OF THE PYTHON
ECOSYSTEM.
BECAUSE IN PYTHON, NORMAL STRING OBJECTS, THE
ONES WE'RE ACCUSTOMED TO DEALING WITH ARE
IMMUTABLE, THEY CAN'T BE CHANGED OR MODIFIED.
THIS IS TRUE OF THE TYPES AVAILABLE UNDER BOTH 2
AND 3.
THE ORIGINAL STRING TYPE, STR, WAS IN PYTHON 3
RENAMED TO BYTES BECAUSE OF ITS LOW-LEVEL NATURE
AND THAT SYNONYM WAS ALSO BACK PORTED TO PYTHON
2.
WE WON'T TALK MUCH TODAY ABOUT THE NEWER UNICODE
BYTE STRINGS THAT WERE RENAMED TO THE STR TYPE,
THE OFFICIAL STRING TYPE OF PYTHON 3.
WE'RE GOING TO BE TALKING ABOUT THOSE LOWER-LEVEL
ONES, THE STRINGS THAT DON'T PRETEND THAT THEY
HAVE SYMBOLS INSIDE OF THEM SO MUCH AS THEY KNOW
THAT THEIR INNARDS ARE REALLY BYTES, 8-BIT CODES
0 THROUGH 255.
FOR THE MOST PART I WILL PUT THAT LITTLE B IN
FRONT OF THE BYTE STRINGS THAT I TYPE.
IT IS OPTIONAL UNDER PYTHON 2 BUT IT BECOMES
MANDATORY UNDER PYTHON 3, SO IF I WRITE MY
STRINGS LIKE THIS, IT WILL WORK WHEREVER YOU TRY
THIS LATER IF YOU WANT TO SEE THE EXAMPLES RUN.
STRINGS ARE IMMUTABLE.
WHAT DOES THAT MEAN IT?
MEANS THAT WHEN YOU CALL METHODS, WHEN YOU DO
THINGS TO THEM, THE ORIGINAL OBJECT ITSELF
DOESN'T CHANGE.
YOU GET GIVEN A NEW OBJECT AS THE RETURN VALUE OF
THE METHOD YOU CALL SO IF DOT LOWER RETURNS TO
YOU A NEW STRING, YOU CAN STILL PEEK BACK AND SEE
THAT THE ORIGINAL IS UNTOUCHED AND UNCHANGED.
IF YOU RUN SPLIT, YOU'LL SEE THAT BOTH OF THE
OBJECTS YOU'VE BEEN GIVEN ARE NEW STRING OBJECTS,
THE ORIGINAL IS STILL UNCHANGED.
THEY DO NOT ALLOW ASSIGNMENT BECAUSE THAT WOULD
MAKE THEM CHANGE, IT WOULD MAKE THEM MUTATE IS
THE TECHNICAL TERM IN COMPUTER SCIENCE.
NOW IMMUTABILITY HAS A LONG AND VERY SUCCESSFUL
CAREER IN PYTHON BECAUSE IT MAKES THINGS SIMPLE
YOU DON'T PASS A NAME TO A FUNCTION ONLY TO
SUDDENLY DISCOVER IT'S ANOTHER NAME WHEN IT COMES
BACK.
YOU DON'T PASS A STRING OR A BLOCK TO SOMEONE AND
SUDDENLY IT'S A DIFFERENT STRING OR BLOCK, IT'S A
VERY, VERY SIMPLE MODEL THAT IF YOU HAVE THE WORD
"PYTHON," YOU KNOW IT WILL ALWAYS REMAIN SO.
AND IT ACTUALLY IS ONE OF THE MOST PARTS OF
PYTHON THAT'S THE MOST LIKE FUNCTIONAL
PROGRAMMING LANGUAGES, WHERE NEW RESULTS ARE
RETURNED INSTEAD OF BEING WRITTEN ON TO DATA
STRUCTURES YOU ALREADY HOLD.
THE STRING TYPES ARE A PRIMARY EXAMPLE OF THAT.
BUT IT SOMETIMES IS A LITTLE EXPRESSIVE IN TERMS
OF ALLOCATION.
ANY TIME YOU WANT TO MAKE A LITTLE TWEAK TO A
STRING, IT HAS TO ALLOCATE A NEW ONE FOR YOU.
THAT MEANS A LOT OF DATA GETS COPIED BACK AND
FORTH INTO NEW AREAS OF MEMORY.
NOT EVERYBODY IS HAPPY ABOUT THAT, AND SO PYTHON
3 INTRODUCED AND THEN IT WAS BACK-PORTED TO
PYTHON 2, 6 AND 7, THE NEW BYTEARRAY.
A BUILT-IN, PYTHON 2-7, PYTHON 3, YOU CAN JUST
TYPE "BYTEARRAY" AND YOU'LL GET ACCESS TO THAT
TYPE JUST LIKE WITH STR AND INT AND LIST.
A BYTEARRAY IS IMMUTABLE STRING THAT IS BASED --
THIS IS INTERESTING -- ON PYTHON 3'S BYTE STRING,
NOT THE OLD STR STRING FROM PYTHON 2.
AND THAT'S AN INTERESTING PROBLEM THAT IT'S BASED
ON PYTHON 3 LEAST BYTE STRING TYPE, BECAUSE,
HONESTLY, THE PYTHON 3 BYTES TYPE IS DESIGNED TO
BE AWKWARD FOR STRING OPERATIONS.
WHY?
SO YOU WILL WANT TO BE A GOOD PERSON AND RUN
DECODE BEFORE TREATING YOUR DATA AS CHARACTERS,
AND THIS HAS LED TO PYTHON 3 PROGRAMMERS TENDING
TO WRITE CODE THAT IS FROM THE GROUND UP PREPARED
FOR INTERNATIONALIZATION AND DIFFERENT ALPHABETS
BECAUSE THEY THINK ABOUT THE ISSUE OF DECODING ON
THE WAY IN AND ENCODING ON THE WAY BACK OUT,
BECAUSE THEY HAVE TO.
BUT WE'LL SEE IT LEADS TO SOME INTERESTING
BEHAVIORS, JUST PROFESSIONALLY, ALWAYS BEWARE OF
USING STRING TYPES THAT WISH YOU WEREN'T USING
THEM.
IN PYTHON 2, LET'S COMPARE.
WE CAN BUILD A STRING, WE COULD ASK ITS LENGTH,
WE CAN SPLIT IT INTO PIECES.
PYTHON 3'S BYTES TYPE.
THERE IS A LITTLE B CHARACTERS HANGING OUT IN
FRONT OF OUR BYTE STRINGS BUT WE CAN TAKE THE
LENGTH, WE CAN CALL A METHOD LIKE SPLIT.
IN PYTHON 2, WE CAN USE THOSE SQUARE BRACKETS
WITH A COLON IN ORDER TO DO SLICING AND GET BACK
A COPY OF THE INSIDE OF THE STRING.
EXACT SAME THING WORKS EXACTLY THE SAME WAY IN
PYTHON 3.
IN PYTHON 2-, IT'S ALWAYS A CUSTOM IN PYTHON, IF
SOMETHING HAS A LENGTH, IT SHOULD ALLOW ITSELF TO
BE ITERATED OR LOOPED OVER.
IN PYTHON 3, IF YOU LOOP OVER A CHARACTER STRING,
YOU GET ONE CHARACTER STRINGS THAT ARE INSIDE.
WHAT HAPPENS IF YOU PRINT -- PRESS "ENTER" FOR
THIS LINE OF CODE IN PYTHON 3?
YOU GET A SYNTAX ERROR.
SYNTAX ERROR.
YOU FAILED TO PAY THE PYTHON 3 PAREN TAX.
[ Laughter ]
PYTHON 3 IS KIND OF LIKE AN OLD TEXT-BASED
ADVENTURE GAME WHERE YOU CAN TELL THE WRITER JUST
THREW AN EXTRA OBSTACLE IN YOUR WAY BECAUSE THE
ROOM NEEDED TO BE A LITTLE MORE COMPLICATED.
YOU KNOW, IN -- YOU KNOW, IN THE -- IN SERIOUS...
[ Applause ]
IN SERIOUSNESS, I'VE KNOWN SOME RUBY PROGRAM
YEARS, THIS IS A BIG DEBATE IN THE RUBY
COMMUNITY.
RUBY MAKES PARENTHESES OPTIONAL WHEN CALLING A
FUNCTION.
THE RUBYISTS WHO NEVER USE PARENTHESES ALWAYS
TELL ME THEY COULD NEVER STAND PYTHON AGAIN AND I
THOUGHT THAT WAS THE ODDEST THING.
DOESN'T EVERYONE WANT TO TYPE PARENTHESES
WHENEVER THEY ASK THEIR COMPUTER TO DO SOMETHING?
AND I MUST ADMIT THAT ONCE IT WAS ME WHO WAS
SUDDENLY HAVING TO TYPE PARENTHESIS, BUT THEY
SURELY MUST STILL BE WRONG.
ANYWAY...
I DID A CONSERVATIVE ESTIMATE OF HOW MUCH TYPING
IS COST ME BY THESE PRINT STATEMENTS IN PYTHON 3
AND THIS IS -- THESE ARE CONSERVATIVE ESTIMATES,
AND IT'S COMING OUT TO QUITE A BIT OF TYPING PER
YEAR.
I'M HAVING TO FACE GOING INTO PAREN DEBT JUST TO
WRITE SOME EMARKS LISP NEXT WEEK.
ANYWAY, PYTHON 3 WANTS THEM FOR THIS PRINT
STATEMENT AND WHAT'S ANOTHER 2 PARENS WHEN I'VE
ALREADY TYPED SO MANY?
ONCE YOU GET THE PRINT STATEMENT WORKING, YOU'RE
IN FOR ANOTHER SURPRISE.
PYTHON 3 BYTES TYPE IS NOT MADE OF CHARACTERS, IT
IS MADE OF NUMBERS.
THIS BREAKS A VERY IMPORTANT CONTRACT THAT, FOR
ME, EXISTED WITH STRINGS WHICH IS THAT I CAN PULL
THEM INTO PIECES WITH EITHER INDEXING OR SLICING
AND KNOW THAT THEY WOULD GO BACK TOGETHER AGAIN.
NOW, THERE IS A WAY AROUND BY ASKING FOR ONE
ELEMENT SLICES INSTEAD OF LOOKING UP INTEGER
INDEXES.
BUT, CLEARLY, IT DOESN'T WANT ME TO TREAT IT LIKE
A STRING.
SO BYTES OBJECTS EVEN IF YOU LEARN SOME
WORK-AROUND ARE KIND OF AN AWKWARD FIT FOR MANY
OF THE TASKS THEY'RE CALLED UPON TO DO.
THEY'RE KIND OF THIS HYBRID TYPE BETWEEN A LIST
OF NUMBERS AND A STRING.
THEY ARE KIND OF IN-BETWEEN AND THEY DON'T
NECESSARILY DO EITHER ONE PERFECTLY WELL.
SO WHY DO I BRING ALL OF THAT UP?
WHY DO I REHEARSE THESE WELL-KNOWN ISSUES WITH
PYTHON 3 BYTES WHICH, BY THE WAY, ARE BEING TAKEN
CARE OF.
PYTHON 2-5 WILL REINTRODUCE PERCENT FORMATTING
FOR BYTE STRINGS BECAUSE NOW THAT THE EXPERIMENT
IS IN ITS FIFTH VERSION, I THINK IT IS BEGINNING
TO BECOME CLEAR THAT THE REAL PROBLEM IN PYTHON 2
WASN'T THAT STRINGS WERE CONVENIENT, AND SO WE
IGNORE UNICODE, IT'S THAT CONVERSION COULD HAPPEN
AUTOMATICALLY WITHOUT WARNING.
AND SO THEY ARE BEGINNING TO ADD POWER BACK INTO
PYTHON 3 BYTE STRINGS BUT THEY PROBABLY WILL
ALWAYS BE MADE OF NUMBERS NOW FOR BACKWARDS
COMPATIBILITY AND WE BRING ALL THAT UP BECAUSE
THE BYTEARRAY THAT I WILL NOW TALK ABOUT IS A
MUTABLE VERSION OF PYTHON 3'S BYTE STRING, A
MUTABLE VERSION OF PYTHON'S MOST UNDERPOWERED
STRING TYPE.
SO WE'LL JUST QUICKLY LOOK AT A FEW POSSIBLE
APPLICATIONS AND WHETHER A MUTABLE VECTOR OF
BYTES IS ABLE TO ACCOMPLISH THINGS BETTER OR
WORSE THAN TRADITIONAL PYTHON.
SO, FIRST, LET'S BE FAIR TO IT.
WHAT IF YOU ACTUALLY WANT A LIST OF NUMBERS
BETWEEN ZERO AND 255?
THAT NEVER HAPPENS TO ME.
[ Laughter ]
SO I INVENTED -- IN THOSE RARE CASES WHERE YOU
ACTUALLY WANT TO STORE BYTES, IF YOU HAD ONE, IS
THE BYTEARRAY A GOOD CHOICE.
SO I INVENTED ONE.
I WROTE MY FIRST BLOOM FILTER AS PREPARATION FOR
THIS TALK, A BLOOM FILTER IS A WAY TO -- LET'S
SAY YOU HAVE A DICTIONARY OF WORDS AND BEFORE YOU
GO LOOK ON DISK FOR WHETHER WORD IS IN YOUR
DICTIONARY, YOU WANT A QUICK WAY TO KNOCK OUT A
LOT OF WORDS, IT'S JUST NOT BEING CANDIDATES.
WHAT YOU CAN DO IS SET UP A BIG BIT FIELD AND
HAVE A COUPLE OF HASH FUNCTIONS THAT YOU THROW
THE WORLD "ELEPHANT" AT THEM AND THEY IDENTIFY
SOME BITS FOR YOU THAT BELONG TO "ELEPHANT."
YOU GIVE THEM THE WORD "PYTHON," A DIFFERENT SET
OF BITS.
THE IDEA IS THAT IF YOU LOAD UP YOUR DICTIONARY
BY SETTING ALL OF THE BITS FOR ELEPHANT AND ALL
THE BITS FOR PYTHON, THEN WHEN YOU SEE THOSE
WORDS LATER IN A DOCUMENT, YOU CAN JUST CHECK
WHETHER THEY'RE BITS ARE SET TO KNOW IF THERE'S
ANY POSSIBILITY THAT "ELEPHANT" IS IN YOUR
DICTIONARY BECAUSE MANY WORDS WILL HAVE SETS OF
BITS THAT AREN'T SET AT ALL AND SO -- OR SEVERAL
OF WHICH AREN'T SET AND THAT YOU KNOW COULD NOT
HAVE BEEN IN THE DICTIONARY YOU LOADED.
THIS IS A NICE EXAMPLE BECAUSE IT LETS US DO A
PURE MATH OPERATION, IN THIS CASE, THE IN-PLACE
OREING OF A BYTE IN THIS ARRAY A WITH ITSELF, AND
WITH A BIT THAT WE CREATE OVER HERE IN SET.
AND WE CAN RUN THROUGH, SET THIS UP, AND THEN WE
WANT TO TEST A WORTH, GO BACK IN AND USE THE
READING VERSION OF SQUARE BRACKETS, NOT IN AN
ASSIGNMENT STATEMENT BUT IN AN EXPRESSION, TO
READ BACK THE VALUE OF A BIT.
A NICE EXERCISE TO SEE HOW DOES THIS THING
PERFORM, STORING AND RECEIVING A FEW TENS OF
THOUSANDS OF BYTES.
BY THE WAY, THE NAME A IN THE PREVIOUS CODE CAN
BE EITHER AN OLD-FASHIONED ARRAY.ARRAY THAT'S
BEEN AROUND IN PYTHON FOREVER, OR A NEW-FANGLED
BYTEARRAY.
TO THIS EXTENT, THEY BOTH PROVIDE THE SAME
INTERFACE, EACH SLOT YOU CAN ADDRESS GETS YOU OR
LET'S YOU STORE A BYTE.
AND SO WITH THIS APPLICATION, I RAN IT BOTH WAYS
AND BYTEARRAY SCORED ITS FIRST VICTORY, BECAUSE
IT IS SO MORE SPECIFIC THAN ARRAY.ARRAY WHICH I
BELIEVE CAN ALSO HOLD FLOATS AND INTEGERS AND
THINGS LIKE THAT, BECAUSE THE BYTEARRAYS CODE
PATH HAS ALMOST NO DECISIONS, IT IS ALMOST ALWAYS
GOING TO STORE BYTES, IT IS ALMOST 7% FASTER FOR
RUNNING THAT BLOOM ARRAY CODE THAT I JUST SHOWED
YOU THAN THE ORIGINAL PURPOSE ARRAY.ARRAY
PURPOSE.
SO YOU MIGHT THINK THIS IS IMMEDIATELY AND
OBVIOUSLY A GO-TO DATA STRUCTURE FOR LISTS OF
8-BIT NUMBERS.
I TRIED IT ANOTHER WAY.
I WANT WANT TO KNOW WHAT'S EVEN FASTER THAN
ANOTHER BYTE AWAY?
A LIST OF INTEGERS.
1% FASTER.
IF YOU JUST SAY, HEY, PYTHON, HERE'S A
ONE-ELEMENT LIST WITH A 0 IN IT, MAKE ME A LOT OF
THESE.
A PLAY -- SORRY, 2%, A PLAIN LIST OF INT OBJECTS
THAT HAPPEN TO BE IN THE RANGE 0 TO 255, IT WILL
RUN EVEN FASTER THAN THE BYTEARRAY.
WHY?
WELL, IT'S BECAUSE, THINK OF WHAT THE BYTEARRAY
IS DOING.
IT'S STORING REAL BYTES.
LOW-LEVEL IN YOUR COMPUTER, THAT MUST EACH BE
TRANSLATED INTO AN INT OBJECT ADDRESS WHEN THE
VALUE IS BEING HANDED OUT INTO YOUR PYTHON CODE,
AND THEN WHEN AN INT VALUE -- EXCUSE ME, YEAH,
WHEN AN INT OBJECT IS HANDED BACK, IT HAS TO BE
CHANGED BACK INTO A SIMPLE BYTE IN ORDER TO BE
STORED.
THE LIST SKIPS ALL THAT.
IT JUST STORES THE ADDRESSES YOU GIVE IT.
THE -- NOW, THE BYTEARRAY, BY THE WAY, DOESN'T
HAVE TO PAY ANY PENALTY TO ALLOCATE OR CREATE ANY
OF THOSE INT OBJECTS BECAUSE IT JUST SO HAPPENS
THAT THE PYTHON -- THE CPYTHON INTERPRETER, WHEN
IT STARTS UP PREALLOCATES ALL THE INTEGER OBJECTS
NEGATIVE 5-256 SO THEY NEVER HAVE TO BE CREATED
OR DESTROYED OVER THE LIFETIME OF THE
INTERPRETER.
SO WHEN YOU ASK THE BYTEARRAY WHAT'S AT POSITION
100 AND IT WANTS TO SAY 70, IT CAN GRAB THE
EXISTING 70 INTEGER OBJECT THAT ALWAYS EXISTS IN
MEMORY AND HAND IT BACK SO IT'S NOT HAVING TO GO
DO A MALLACK OR ANYTHING, IT'S NOT HAVING TO GOOD
MEMORY BUT IT STILL HAS TO DO THE STEP OF
TRANSLATION AND IT'S HONESTLY EASIER TO STORE THE
ADDRESS OF THE 70 OBJECT.
THAT'S WHY THE LIST OBJECT RUNS FASTER, AND SO
THIS IS INTERESTING.
WE HAVE THIS NEW SPECIAL CASE CONTAINER THAT'S
SLIGHTLY SLOWER THAN JUST USING PYTHON'S
WELL-HONED DEFAULT DATA TYPES.
A PLAIN OLD LIST IS A FASTER BIT VECTOR THAN THE
FANCY NEW BYTEARRAY.
EXCEPT IF YOU'RE USING PYPY, WHERE THEY'RE ALL
THE SAME BECAUSE IT BECOMES THE SAME C-CODES
UNDER THE HOOD -- MACHINE CODE, I SHOULD SAY, AND
ALL THREE RUN MUCH FASTER AS WELL AS BEING
EXACTLY EQUIVALENT.
I TRIED IT OUT IN PYPY, IN EACH CASE FIGURED OUT
I WAS TRYING TO DO EXACTLY THE SAME THING.
I GUESS THEY'RE DONE ALREADY.
I'LL JUST KEEP GOING.
SO FOR THIS FIRST EXPERIMENT, WHAT IF I NEED A
LIST OF INTEGERS BETWEEN 0 AND 255?
MY VERDICT IS THAT THE BIT VECTOR IS SPACE
EFFICIENT.
YOU DON'T CHOOSE IT BECAUSE IT'S GOING TO BE
OBVIOUSLY FASTER, IT'S NOT, OR OBVIOUSLY SIMPLER,
IT'S DOING A LITTLE MORE UNDER THE HOOD.
BUT THE GOOD, OLD-FASHIONED LIST OF INTEGERS HAS
TO STORE IN EACH SLOT THE ADDRESS OF THE REAL
INTEGER OBJECT 70.
THE BIT VECTOR JUST STORES THE 7 BITS -- 8 BITS
THAT REPRESENT 70 AND, THEREFORE, USES ON A
64-BIT MACHINE, WHICH IS WHAT I'LL PRESUME FOR
ALL OF THESE CALCULATIONS, EIGHT TIMES LESS
SPACE.
AND THE POINT AFTER A BLOOM FILTER IS TO SAVE
SAYS IN RAM.
THAT FOR BIT OPERATIONS IS WHY YOU GO TO THE
BYTEARRAY BECAUSE IT SCORES BYTES AS HONEST TO
GOODNESS BYTES WITH NO EXTRA OVERHEAD PER BYTE.
IT'S A GREAT WAY TO GET NUMBERS BETWEEN 0 AND
255, PACKED IN THE MINIMUM SPACE POSSIBLE.
SO IT IS A WIN BUT NOT IN THE WAY YOU MIGHT
INITIALLY EXPECT.
ALL RIGHT.
SECOND, IT IS A RE-USABLE BUFFER, WHEN YOU READ A
STRING THIS, YOU CAN'T DO ANYTHING TO IT BECAUSE
IT'S IMMUTABLE BUT A BYTEARRAY CAN BE REUSED.
FOR A QUICK BENCHMARK, I GOT -- MADE A RANDOM
FILE OF A GIGABYTE OF RANDOM DATA, READ IT WITH
CAT SO I WAS ABLE TO ESTIMATE THAT PROBABLY
PYTHON WON'T BE ABLE TO DO BETTER THAN .11
SECONDS ON MY MACHINE, READ CRINGE IN THE SAME
DATE AT THAT TIME I TRIED IT WITH TCP.
ANYONE HERE EVER USE TCP TO REWRITE DATA?
IT TOOK SIX TIMES LONGER.
ANYONE KNOW WHY?
I STRACED THEM AND IT'S BECAUSE OF THE BLOCK
SIZE.
DD, ALAS, IS AN OLD AND CRAFTY AND LOW-LEVEL
TOOL, WHILE CAT WILL ZOOM ALONG WITH 128K BLOCKS,
SO IT ASKS THE OS FOR SOME DATA AND GETS 128,000
BYTES IN A SINGLE SHOT.
DD, BECAUSE IT'S AN OLD-LEVEL FOR WRITING TO
ANCIENT 70s BLOCK DEVICES READS AND WRITES
5R.512 BYTES BY DEFAULT, GIVING DD THE SAME BLOCK
SIZE DOES MAKE IT PERFORM THE SAME, YOU CAN GIVE
IT A BLOCK SIZE OF 128K AND GETS .11 SECONDS
RIGHT THERE WITH CAT BUT IT'S NOT THE DEFAULT
DESPITE I SAME TO KNOW ALL THESE PEOPLE THAT
THINK DD WOULD BE FASTER BY DEFAULT.
IT'S NOT.
IT'S THE SAME READS AND WRITES.
AND CAT IS THE SAME -- DD CAME FROM IBM.
BUT THIS TEACHES US A FIRST LESSON THAT WE WILL
NOW APPLY AS WE LOOK AT PYTHON I.O., WE NEED TO
KEEP BLOCK SIZE IN MEANT, THE SIZE OF THE CHUNKS
YOU READ DETERMINES HOW MANY CHUNKS YOU NEED TO
READ, DETERMINES HOW OFTEN YOU NEED TO CONVERSE
WITH THE OPERATING SYSTEM.
WHICH IS OFTEN THE EXPENSE THAT CAN COME TO
DOMINATE YOUR RUN TIME.
HERE'S HOW WE DO IT IN NORMAL PYTHON.
READ A BLOCK AND WRITE THE DATA BACK OUT.
NOTE, THIS IS PERFECTLY SAFE IF AN UNDERSIZED
BLOCK COMES IN BECAUSE THE STRING THAT I'M HERE
CALLING DATA THAT COMES BACK IS LABELED WITH ITS
LENGTH.
IT COULD BE 5 BYTES, IT COULD BE 128K, IT --
PYTHON STRINGS KNOW THEIR LENGTH AND SO WRITE CAN
JUST ASK THE LENGTH AND SEND THAT MANY BYTES OF
DATA BACK OUT.
MY FIRST ATTEMPT AT DOING A READ INTO SEEMED TO
WORK, AT FIRST, UNTIL I NOTICED THAT EVERY FILE I
WROTE, HOWEVER BIG IT WAS ORIGINALLY, THE COPY
THAT I MADE WITH THIS ROUTINE WOULD ALWAYS BE A
MULTIPLE OF MY BLOCK SIZE.
WHY IS THAT?
BECAUSE WHEN I CREATE ONE OF THESE NEW BYTEARRAYS
OF, LET'S SAY, 128K, WHAT THIS LOOP WAS DOING IS
READING SOME NUMBER OF BYTES, WHO KNOWS HOW MANY
COME IN IN THE NEXT BLOCK OF THE FILE IF I'M NEAR
THE END, READS SOME NUMBER OF BYTES INTO ANY
BYTEARRAY, AND THEN WRITES OUT THE WHOLE
BYTEARRAY, INCLUDING ALL THE JUNK AT THE END
THAT'S MAYBE NOT PART OF THE CURRENT BLOCK OF THE
FILE.
I WAS DOING MY WRITE OF THE WHOLE 128K BLOCK
WITHOUT CONSULTING THE LENGTH TO SEE IF I SHOULD
HAVE BEEN WRITING THE ENTIRE 128K BLOCK.
ONE FIX IS TO SIMPLY USE SLICING.
IS TO GET THAT BYTEARRAY CALLED DATA AND TAKE
FROM IT TO WRITE EACH TIME THE SLICE THAT IS
LENGTH LONG.
SO IF I GET A FULL-SIZED BLOCK, I'M WRITING OUT
ALL OF THE DATA, BUT IF I GET ONLY HALF A BLOCK
AT THE END OF THE FILE, I ONLY WRITE THAT --
WELL, LAST HALF BLOCK OUT FROM THE INITIAL PART
OF MY BYTEARRAY.
WHAT IF WE DIDN'T WANT THE EXPENSE, THOUGH, OF
HAVING TO DO THAT, BACK ONE SLIDE, EXPENSIVE
SLICING OPERATION, BECAUSE ASKING A PYTHON STRING
UNICODE STRING OR BYTEARRAY FOR A SLICE CREATES A
WHOLE NEW ONE, AND COPIES AS MUCH DATA INTO THE
NEW ONE AS YOU ASK FOR WITH THE LIMITS YOU SET IN
THE SLICE.
IF WE WANT TO ACHIEVE ZERO COPY, THE PEOPLE WHO
ADDED BYTEARRAY TO THE LANGUAGE, THEY THOUGHT OF
THAT, AS WELL.
THEY ADDED A SECOND FEATURE THAT WORKS WITH
BYTEARRAY CALLED A MEMORY VIEW.
A MEMORY VIEW IS A SLICEABLE OBJECT.
HERE I TAKE THE SLICE 3:6 OF THAT BYTEARRAY, IT'S
A SLICE WITH NO MEMORY OF ITS OWN BUT IS LETTING
YOU REACH INTO THE MEMORY IT WAS SLICED FROM TO
MAKE THE CHANGE.
ESSENTIALLY THIS MEMORY VIEW, THE "V" THAT I
CREATE HERE, IS JUST A -- ESSENTIALLY, IT'S LIKE
A STRING OBJECT BUT THE ADDRESSES IT WANTS TO
WRITE TO IN MEMORY ARE THE ADDRESSES RIGHT THERE
IN THE MIDDLE OF THE BYTEARRAY, SO WHEN I TRY TO
SET ITS INDEX 0 VALUE, IT REALLY GOES TO INDEX 3
IN THE REAL BYTEARRAY.
WHEN I SET ITEM 1, IT REALLY GOES TO SLOT 4.
WHEN I SET ITEM 2, IT GOES TO SLOT 5.
IT REALLY IS JUST CREATING AN OBJECT THAT ACTS
LIKE IT'S A ALSO BYTEARRAY BUT IS, IN FACT, JUST
AN OFFSET.
IT'S ADDING SOMETHING TO EACH INDEX YOU USE AS
YOU READ AND WRITE FROM IT.
AND THIS IS WHAT CAN HELP US IN THE SITUATION
WE'RE IN.
HERE IS A 0 COPY VERSION OF MY FIXED CODE TO TRY
TO READ IN LOTS OF BLOCKS.
BEFORE, I WAS ASKING DATA, THE BYTEARRAY ITSELF
TO DO THE SLICING AND, LIKE ALL PYTHON STRINGS,
IT GIVES ME A WHOLE NEW ONE WHEN I ASK FOR A
SLICE.
NOW I'M LOOKING AT IT THROUGH A MEMORY VIEW SO IF
I ASK, LET'S SAY, FOR VIEW OF -- YOU KNOW, IF
LENGTH IS 128K, I'M ASKING FOR ALL THE DATA, IT
JUST GIVES ME A LITTLE MEMORY VIEW OBJECT WHOSE
ADDRESSES ARE POINTING AT THE WHOLE BLOCK OF
DATA, A VERY CHEAP OPERATION, AND SO MEMORY VIEWS
ARE OFTEN NECESSARY TO GET THINK KIND OF
PERFORMANCE OUT OF THE BYTEARRAY WHEN DOING IO,
ESPECIALLY WHEN YOU CAN'T PREDICT HOW BIG THE
NEXT DELIVERY OF INFORMATION WILL BE.
HERE ARE THE RUNTIMES OF DD AND CAT THAT WE
DISCUSSED EARLIER.
COMPARED TO JUST PLAIN OLD READ, WITH NORMAL
PYTHON STRINGS, READ INTO, MY FIRST VERSION THAT
WAS BROKEN BECAUSE IT WASN'T CAREFUL ABOUT HOW
MUCH IT WROTE, DOES RUN SLIGHTLY FASTER THAN THE
TRADITIONAL PYTHON WAY OF DOING THINGS, BUT WHEN
YOU THEN PIVOT TO USING A SLICE BYTEARRAY AND
SLICING IT, BECAUSE YOU'RE COPYING EVERY PIECE OF
DATA INTO MEMORY TWICE, IT'S MUCH MORE EXPENSIVE.
IT IS THE MEMORY VIEW, IT IS THAT ZERO EXPENSE,
VERY LITTLE EXPENSE, CONSTANT TIME EXPENSE, I
SHOULD SAY, ABILITY TO SLICE WITHOUT COPING DATA,
THAT LETS US CREATE A CORRECT VERSION OF A FILE
COPY WITHOUT -- WHILE STILL SLIGHTLY BEATING READ
AND WRITE.
AND TRADITIONAL STRINGS.
SO THAT WAS A LOT OF WORK, AND WE GOT A 4%
SPEED-UP WITH BYTEARRAY.
NOW, SMALL BLOCKS, THINGS GET WORSE FOR
BYTEARRAY.
BECAUSE WHAT WILL SLICING HERE SO OFTEN DO, IT
CREATES A NEW OBJECT EVERY TIME AND CREATING ONE
OF THESE LITTLE VIEW OBJECTS WITH ITS HE POINTERS
IN THE PART OF THE BYTEARRAY I WANT TO LOOK AT
WAS FINE WHEN I WAS ONLY DOING IT EVERY FEW
HUNDRED K OF DATA BUT WHAT IF I WANT THE DEFAULTS
OF DD AND I'M GOING TO BE RUNING 1200 BYTES AT A
TIME, WHAT IF I HAVE TO SPIN UP A NEW MEMORY VIEW
FOR EVERY HALF K OF DATA?
THEN THINGS START TO LOOK VERY BAD AND, IN FACT,
THE MEMORY VIEW USED CORRECTLY, WHERE YOU'RE
CAREFUL OF YOUR LINKS, IS SIMPLY A LOSS.
IT'S MUCH -- READING, WHERE IT JUST RETURNS A
PYTHON STRING IS REALLY EFFICIENT.
A WRITE OF A PYTHON STRING IS REALLY EFFICIENT.
YOU CAN EASILY GET INTO SITUATIONS WITH THE FANCY
ATTEMPTS ONE MAKES WITH A BYTEARRAY TO CREATE
MORE EXPENSIVE IO THAN YOU HAD WHEN YOU JUST USED
TRADITIONAL IMMUTABLE STRINGS THAT, YES, REQUIRED
PYTHON TO BUILD A NEW STRING FOR EVERY CALL TO
READ BUT CUT OUT ALL OF THE REST OF THAT EXPENSE.
I WAS SAD FOR THE BYTEARRAY.
AT THIS POINT IN MY TALK.
SO I STARED AT THE EXAMPLE.
20% SLOWDOWN FOR A SMALL BLOCK SIZE.
BUT THEN, I THOUGHT OF SOMETHING.
WHAT IF WE DON'T ALWAYS SLICE, BECAUSE WHEN
READING FROM A FILE, DIFFERENT FROM A NETWORK,
WHEN READING FROM A FILE, THE NORMAL CASE IS THAT
UNLESS YOU'RE AT THE VERY END OF THE FILE, YOU'RE
GOING TO GET AS MUCH AS YOU ASK FOR.
ASK FOR 128K, YOU'RE GOING TO GET IT.
THE NORMAL CASE IS THAT THE LENGTH EQUALS THE
BLOCK SIZE AND IN THAT CASE, THERE'S NOT ONLY NO
REASON TO ASK THE BYTEARRAY TO TAKE A SLICE OF
ITSELF AND COPY ALL THAT DATA, THERE'S NO REASON
TO USE THE VIEW TO LIMIT THE AMOUNT OF DATA
YOU'RE USING FROM THE BLOCK.
YOU'RE GOING TO USE ALL OF IT AND SO IF YOU
HANDLE THAT SPECIAL CASE, YOU DON'T INCUR AN
OBJECT CREATION STEP IN ORDER TO GET THAT WRITE
CALL STARTED, AND YOU SLIGHTLY BEAT THE
PERFORMANCE OF THE TRADITIONAL READ-WRITE LOOP BY
4%.
JUST LIKE...
JUST LIKE FOR THE BIG BLOCK CASE, SO EVEN IF YOUR
IO IS IN A SITUATION WHERE THE BLOCK SIZE WILL BE
VARYING OR MIGHT BE SMALL, YOU CAN, IF YOU'RE
CAREFUL AND CUT AND PASTE FROM MY TALK SLIDES,
YOU CAN RUN SLIGHTLY FASTER THAN THE TRADITIONAL
READ AND WRITE WITH IMMUTABLE DRINKS.
PYTHON 2.7, BY THE WAY, HAS THE SAME RELATIVE
BEHAVIORS BETWEEN THOSE DIFFERENT CHOICES ON MY
MACHINE, SLIGHTLY SLOWER.
AND I THINK THE LESSON HERE IS THAT IT IS JUST
HARD TO BEAT OLD-FASHIONED STRINGS WHEN YOU'RE
PULLING IN DATA AND THEN JUST IMMEDIATELY SENDING
IT BACK TO THE OPERATING SYSTEM OVER SOME OTHER
CHANNEL.
IT'S REALLY SOMETHING HOW THE GOOD-OLD-FASHION
IMMUTABLE STRING THAT MAKES FUNCTIONAL
PROGRAMMERS' HEARTS SING IS PRETTY MUCH AS GOOD
IN THIS CASE AS OUR WEIRD SIDE EFFECTY IDEA OF
CONSTANTLY MODIFYING THIS SINGLE BYTES ARRAY THAT
WE HAVE CREATED.
SO, MY VERDICT IS THAT IT IS DANGEROUS, BECAUSE
IT'S SO EASY TO WRITE WHAT LOOKS LIKE PRETTY
CODE, IT LOOKS LIKE ALMOST THE SAME LITTLE
READ-WRITE LOOP BUT GOING TO OPERATE
SUBSTANTIALLY WORSE IN SITUATIONS THAT YOU MIGHT
NOT THINK TO TEST FOR UNLESS YOU THINK OF THE
SMALL BLOCKS INDICATION.
THE ONE ADVANTAGE IT DOES OFFER IS A GREAT MEMORY
PROFILE BECAUSE THERE IS A LINK LATER TO A GREAT
BLOG POST ONLINE ABOUT SOMEONE WRITING AN AUDIO
SERVER THAT NEEDED TO KEEP LOTS OF STRINGS IN A
BUFFER AND HIS MEMORY USAGE WAS GOING THROUGH THE
ROOF BECAUSE IF YOU'RE CONSTANTLY ALLOCATING AND
DE-ALLOCATING DIFFERENTLY SIZED STRINGS BECAUSE
EVERY CALL TO READ NEEDS TO MAKE A NEW STRING TO
HANDS IT BACK TO YOU, THEN YOU CAN GET A LOT OF
MEMORY FRAGMENTATION.
IF INSTEAD YOU HAVE ONE BYTEARRAY AND YOU USE IT
OVER AND OVER AND OVER AND OVER, THERE'S NOTHING
HAPPENING TO GET FRAGMENTED.
SO DON'T DO THE BYTEARRAY.
I WOULDN'T DO THE BYTEARRAY FOR THE 4% SPEED-UP.
I WOULD DO IT BECAUSE I WANTED TO CONTROL MY
MEMORY PROFILE BUT ONLY IF I KNEW THAT WAS A
PROBLEM IN MY APPLICATION DOMAIN.
NOW WICK GO ON TO ANOTHER AND MORE INTERESTING
SITUATION, USING THE BYTEARRAY AS THE
ACCUMULATOR.
FUN QUESTION FOR PEOPLE DOING NEW NETWORK
PROGRAMMING.
HOW MANY BYTES WILL RECEIVE 1024 RETURN?
THE ANSWER IS...
ONE.
OR MORE, IF THE NETWORK STACK IS IN THE MOOD, BUT
YOU'RE ONLY GUARANTEED ONE, AND THIS IS THE
OPPOSITE OF FILE IO.
FILE IO, YOU ASK FOR 128K, IF THERE'S 128K LEFT
IN THE FILE, IT WILL WAIT FOR THE DISK TO SPIN,
WAIT FOR THE HEAD TO BE IN THE RIGHT PLACE.
IT WILL LEAVE YOU PAUSED UNTIL A FULL 128K IS
READY FOR DELIVERY AND THEN WAKE YOU BACK UP.
THE NETWORK IS THE OPPOSITE.
RECEIVE WILL BLOCK ONLY UNTIL AT LEAST A SINGLE
BYTE IS AVAILABLE AND THEN SET YOU OFF RUNNING TO
PROCESS IT.
AND THAT CAN HAPPEN IF YOUR BUFFER SIZE HAPPENS
TO BE JUST A LITTLE LESS THAN THE SIZE OF THE
LAST FEW PACKETS THAT ARRIVED.
YOU CAN HAVE A CALL TO RECEIVE THAT FIND ONLY ONE
OR TWO BYTES LEFT.
MEANING, UNLIKE IN THE CASE WHERE WE WERE
CHOOSING OUR READ SIZE FOR FILES, USUALLY IT'S
THE NETWORK, IT'S THE CLIENTS, YOU'RE
COMMUNICATING WITH THAT KIND OF DECIDE HOW BIG
YOUR CHUNKS OF IO ARE WHEN YOU'RE TALKING ON THE
NETWORK, SO YOU'RE ALWAYS POTENTIALLY IN THE CASE
WHERE YOU'RE DEALING WITH LITTLE PIECES OF DATA.
THIS FACT, BY THE WAY, THAT YOU ALWAYS ARE GIVEN
AN ANSWER WHEN EACH JUST A FEW BYTES CAN BE SENT
OR RECEIVED IS WHY NEW NETWORK PROGRAMMERS TEND
TO GET INTO THE, "BUT IT WORKED WHEN I RAN
AGAINST LOCAL HOST PROBLEM."
THEY GET INTO THAT SITUATION BECAUSE WHEN YOU RUN
YOUR SERVER THAT YOU'VE JUST WRITTEN IN YOUR
LITTLE CLIENT YOU'VE JUST WRITTEN ON LOCAL HOST,
THE OS WILL SEND ENORMOUS BLOCKS OF DATA BACK AND
FORTH BETWEEN THE TWO PROCESSES.
THEN, THEY'LL TAKE IT TO THEIR TEAM AND SAY, LOOK
WHAT I WROTE, TRY IT BETWEEN TWO DIFFERENT
MACHINES.
AND IT WILL HANG AND NEVER GET ALL THE DATA
BECAUSE THEY DIDN'T LEARN ON LOCAL HOST THAT YOU
RECEIVE WILL OFTEN JUST GIVE YOU A FEW THOUSAND
BYTES AND YOU NEED TO KEEP AT IT AND WATCH UNTIL
EVERYTHING YOU NEED HAS ARRIVED.
SO WHAT IS IT LIKE TO USE A TRADITIONAL RECEIVE
SOLUTION GETTING A NEW STRING EACH TIME, HOLDING
THE NEW DATA THAT'S COME IN?
THIS IS WHAT IT LOOKS LIKE, AND, AGAIN, HERE,
WE'RE GETTING LOTS OF MAYBE LITTLE PIECES OF DATA
WHICH I'M SIMULATING BY ONLY ASKING FOR A SINGLE
ETHER NET PACKAGE LENGTH SO EACH WHEN I RUN THIS
ON LOCAL HOST, IT WILL PRETEND LIKE PACKETS ARE
COME IN.
AND THE -- THIS IS WHAT MANY PYTHON PROGRAMMERS
START WITH, THEY JUST CREATES AN EMPTY STRING AND
THEY PLUS-EQUAL MORE DATA TO IT EACH TIME.
IN PYTHON TUTORIALS, YOU DOUBTLESS -- MANY OF YOU
WILL HAVE SEEN THIS, THE CREATING OF THE STRING
AND DATA PLUS EQUALS MORE AS AN ANTI-PATTERN THAT
YOU AVOID BECAUSE I TRIED RUNNING THIS.
HOW LONG DOES IT IS PLUS-EQUALS APPROACH TAKE?
INFINITY TIME, MEANING THAT I FINALLY NEEDED MY
LAPTOP BACK SO I KILLED IT AND I'LL NEVER NOW HOW
LONG THE LOOP WOULD HAVE TAKEN TO READ MY BIG
ABYTE OF DATA BUT WHEN YOU DO PLUS-EQUALS, YOU'RE
ASKING PYTHON TO CLEATS A LITTLE STRING AND THEN
YOUR FIRST PLUS-EQUALS MAKES A SLIGHTLY LONGER
ONE.
YOUR NICKS PLUS-EQUALS THROUGH THE LOOP CREATES A
SLIGHTLY LONGER ONE INTO WHICH ALL THE DATA FROM
THE SECOND STRING HAS TO BE COPIED TO MAKE THE
THIRD ONE AND NOW YOU HAVE TO GO THROUGH THE LOOP
AGAIN AND COPY ALL THAT DATA AGAIN TO MAKE YOUR
FOURTH STRING AND IF YOU HAVE A MILLION BYTES TO
READ, YOU WIND UP DOING HALF A TRILLION
OPERATIONS.
IT'S CALLED AN ORDER IN SQUARED ALGORITHM,
GENERALLY TO BE AVOIDED IF YOU WANT IT TO FINISH
BY LUNCHTIME.
SO THIS IS WHAT WE TELL EVERYONE TO DO.
PIVOT TO KEEPING A LIST OF BLOCKS THAT YOU'VE
RECEIVED AND JOIN THEM TOGETHER AT THE END IN A
SINGLE STEP, PYTHON'S MUCH BETTER AT THAT.
THIS ACTUALLY FINISHED ON MY LAPTOP, IT IS
TRADITIONAL WAY OF ACCUMULATING DATA FROM THE
INTERNET ON PYTHON OR FROM A NETWORK, TOOK ABOUT
A LITTLE MORE THAN A SECOND TO READ IN A GIG OF
DATA IN THOSE SMALL 1.5K CHUNKS.
NOW, THERE IS A VERSION, LIKE READ INTO, BUT THAT
RECEIVES INTO A BYTEARRAY YOU'VE ALREADY BUILT
INSTEAD OF BUILDING A NEW STRING, BUT IT NOW RUNS
INTO A PROBLEM.
WHEN WE DO READ INTO, OR RECEIVE INTO, WHERE DOES
IT PUT THE DATA?
AT THE BEGINNING OF THE ARRAY AND ALL OF OUR
INCOMING BLOCKS WILL OVERWRITE EACH OTHER.
WHOA WE WANT AS MORE AND MORE BLOCKS COME IN FROM
THE NETWORK, IS TO ARRAIGNING THEM ALONG OUR
BYTEARRAY.
SO THAT MEMORY VIEW SLICING EXPENSE THAT I ADDED
AN "IF" STATEMENT TO AVOID WHENEVER POSSIBLE IN
THE PREVIOUS CODE?
IT NOW BECOMES MANDATORY.
AGAIN, THIS ABILITY WITH A VIEW TO WRITE INTO
BYTE LOCATIONS THAT AREN'T AT THE BEGINNING BUT
ARE SOMEWHERE IN THE MIDDLE OF THE BYTEARRAY
YOU'VE BUILT.
THE FIRST BLOCK CAN GO AT THE BEGINNING BUT YOU
NEED TO BUILD A MEMORY VIEW TO TARGET THE SECOND
BLOCK AFTER THE FIRST BLOCK.
THE THIRD BLOCK AFTER THAT, AND SO FORTH.
AND SO YOU NEED TO BUILD A MEMORY VIEW AND YOU'RE
GOING TO NEED TO USE IT TO TARGET THAT RECEIVE V
INTO AT SUBSEQUENT POSITIONS INSIDE OF YOUR BIG
BYTEARRAY, PRESUME THAT YOU KNOW THE CONTENT
LENGTH AHEAD OF TIME AND IF PREALLOCATED IT AND
YOU'RE WAITING TO FILL IT WITH DATA.
THIS TAKES ABOUT EIGHT-TENTHS OF A SECOND BECAUSE
WE -- A BIT OF A WIN HERE BECAUSE YOU HAVEN'T HAD
TO BUILD A LIST, YOU HAVEN'T HAD TO CALL JOIN,
YOU HAVEN'T BUILT A BUNCH OF INTERMEDIATE CALL
STRUCTURES, IT ACTUALLY IS A SIGNIFICANT WIN WHEN
YOU NEED TO KEEP THE DATA THAT YOU'RE READING
RATHER THAN JUST IMMEDIATELY PASSING IT BACK TO
THE OS.
ANOTHER POSSIBILITY I SAW ON SOMEONE'S BLOG IS TO
DO AN OLD-FASHIONED RECEIVE OF A NEW STRING AND
THEN TRY TO DO A BYTEARRAY EXTEND TO GROW YOUR
BYTEARRAY WITH THESE NEW STRINGS.
IT COPIES THE DATA TWICE BUT DOES GET RID OF THAT
JOIN CONCATENATION.
IT LOOKS SOMETHING LIKE THIS, DATA.EXTEND NEAR
THE BOTTOM.
IT IS NOT A WIN OVER THE NORMAL WAY OF USING
BYTEARRAYS, BECAUSE IT TURNS OUTS BYTEARRAY
EXTEND IS PRETTY INEFFICIENT.
IT ASKS FOR AN ITERATOR OVER ITS ARGUMENT AND
THEN CALLS -- THE ITERATOR'S NEXT FUNCTION OVER
AND OVER FOR EVERY BYTE AND THEN ASKS THE INT
OBJECT WHAT ITS VALUE IS, SO THAT IT CAN THEN PUT
IT IN AN INTERMEDIATE ARRAY, AND THAT INVOLVES
HAVING TO INCREMENT AND DECRIMENT THE NUMBER IT'S
IN AND BY THE TIME YOU'RE DONE, YOU'VE COMPUTED
AT LEAST 40 BYTES OF BAND WIDTH OF RAM EVEN
IGNORING THE ARGUMENTS AND STACKS THAT YOU'RE
PASSING IN ORDER TO GET THAT SINGLE BYTE VALUE
EXTENDED ON TO THE END OF YOUR BYTEARRAY.
PLUS, IT DOESN'T WRITE TO YOU BYTEARRAY.
IT WRITES TO AN INTERMEDIATE BUFFER THAT GROWS
DYNAMICALLY AND THEN DOES THE APPEND WHEN IT'S
DONE SO THAT SHOULD THAT ITERATION DIE PARTWAY
THROUGH, YOU DON'T WIND UP HAVING MODIFIED THE
BYTEARRAY SOME.
IT WANTS TO EITHER SUCCEED OR FAIL AS AN
AUTONOMIC OPERATION.
SO THAT'S WHY IT'S KIND OF SLOW, KIND OF KLUGY,
BUT SEEING THAT BLOGS POST MADE ME ASK A
QUESTION.
DOES THE BYTEARRAY HAVE AN APPEND OPERATION
THAT'S ANY GOOD?
I MEAN, SURELY THE PEOPLE WRITING IT KNEW THAT
WE'D WANT TO DO THAT BUT SPINNING UP AN ITERATOR
AND CALLING IT 1500 TIMES?
DOES IT HAVE AN OPERATION THAT'S REALLY GOOD?
AND, YES, IT DOES.
I READ THE C-CODE TO FIND IT.
NOW, THINK ABOUT IT.
WHERE WOULD YOU PUT THE REAL EXTEND OPERATOR, THE
REAL ABILITY TO MAKE YOUR BYTEARRAY LONGER?
OBVIOUSLY, YOU WOULD HIDE IT BEHIND THE OPERATOR
THAT WE'VE SPENT 20 YEARS TELLING PEOPLE NEVER TO
USE WITH STRING VALUES.
[ Laughter ]
[ Applause ]
THIS MIGHT BE SO DIFFICULT THAT SOME OF YOU WILL
NEVER DO IT BUT IF YOU CAN CONVINCE YOURSELF TO
TYPE THIS AFTER ALL OF THIS TIME, THIS IS
ACTUALLY SOMETHING THAT BYTEARRAYS DO
MAGNIFICENTLY, JUST PLUS-EQUAL THE ADDITIONAL
DATA TO YOUR BYTEARRAY AND YOU WILL BEAT EVEN
RECEIVE INTO'S ABILITY TO GROW YOUR ARRAY WITH
DATA.
SO THIS CASE WHERE WE NEED TO ACCUMULATE AND KEEP
THE WHOLE PAY ROAD IS A REAL WIN FOR THE
BYTEARRAY IN ALL THE APPROACHES AND THERE DON'T
SEEM TO BE SHARP EDGES THAT CAN SUDDENLY MAKE IT
BEHAVE MUCH WORSE THAN THE LISTEN JOIN.
30% SPEED-UP IN THAT LAST VERSION OF THE
ALGORITHM AND CLEANER CODE.
ADMIT IT, YOU'VE ALWAYS WANTED TO JUST JUST --
JUST PLUS-EQUAL, HAVEN'T YOU?
IT'S THE NATURAL WAY TO WRITE IT IN PYTHON AND
THIS IS ONE OF THOSE NEAT INTERSECTIONS WITH WHAT
LOOKS GOOD AND READS ON THE PAGE, AS WELL.
SO I'M NOT GOING TO TALK ABOUT SEND.
YOU MIGHT THINK ABOUT THE FACT THAT I'LL GET INTO
SEND DOESN'T ALWAYS SEND THE WHOLE PAY LOAD BUT
PYTHON HAS LONG HAD YOU COVERED HERE.
PYTHON SOCKETS HAVE FOR A VERY LONG TIME HAD A
SEND ALL THAT SITS IN A LOOP IN C, SENDING
SHORTER AND SHORTER TAILS OF YOUR DATA UNTIL
FINALLY THE OS BUFFERS HAVE BEEN ABLE TO RECEIVE
IT ALL.
SO I DON'T SEE THAT WE NEED BYTEARRAYS FOR THAT.
AND I CAN DECLARE THE BYTEARRAY THE WINNER.
IF YOU NEED AN ACCUMULATOR, IF YOU NEED TO VERY
QUICKLY N A PERFORMANCE-SENSITIVE ENVIRONMENT,
ACCUMULATE A LOT OF INCOMING DATA, IT IS A
NOTICEABLY GOOD WIN WITH TWO DIFFERENT TECHNIQUES
THAT WORK PRETTY WELL.
I'LL BRIEFLY MENTION THAT SOME PEOPLE WANT A
FREESTYLE MUTABLE STRING.
WHEN THEY SEE THE BYTEARRAY, THEY DON'T THINK OF
IO, THEY DON'T THINK OF BLOOM FILTERS AND BIT
VEHICLESTORS, THEY WANT TO MESS WITH A STRING.
THEY WANT A STRING THAT THEY CAN JUST CHANGE.
AND ALL -- I HAVE NOT FOUND YET A GOOD USE FOR
THIS.
AND I'LL SORT OF SHOW YOU WHY IT WINDS UP BEING
AWKWARD.
YOU WANT TO CHANGE PART OF THE PAY LOAD BEFORE
USING, STORING OR RE-TRANSMITTING.
THAT WOULD BE THE USE CASE HERE BECAUSE IF YOU
WANT TO LOWERCASE THE WHOLE THING, YOU HAVE TO
TOUCH ALL THE BYTES ANYWAY SO YOU MIGHT AS WELL
BUILD A NEW ONE.
GOOD THINGS, THE BYTEARRAY IS IMMUTABLE, GET IT
AND CHANGE IT BUT NONE OF THE METHODS THAT IT
SHARES WITH STRINGS DO MUTATION TO IT.
IF YOU CALLED UPPER ON YOUR BYTEARRAY, YOU GET A
NEW BYTEARRAY.
SO YOU HAVE A MUTABLE STRING TYPE THAT DOES
NOTHING STRING-LIKE MUTABLY.
A BYTEARRAY ONLY CHANGES WHEN SUBJECTED TO
LIST-LIKE OPERATIONS, LIKE ASSIGNMENT TO AN INDEX
OR ASSIGNMENT TO A SLICE OR .CLEAR, AND SO THE
RESULT, IF YOU TRY WRITING A NETWORK ALGORITHM OR
SOMETHING WITH THIS IS CURIOUS.
YOU HAVE A MUTABLE STRING, BUT, ALAS, THAT DOES
NO MUTATION PRECISELY WHEN YOU START CALLING ITS
STRING METHODS.
WANTS TO LOWERCASE A WORD ENOUGH TO MAKE A COPY
TO CALL LOWER ON, YOU'RE GOING TO HAVE TO DO
SLICING GIVING YOU A COPY, CALL LOWER, MAKING
ANOTHER COPY AND THEN ASSIGNMENT TO COPY IT A
THIRD TIME BACK INTO THE DATA STRUCTURE IN ORDER
TO GET THAT ACCOMPLISHED.
THERE ISN'T, I LOOKED, THERE ISN'T A LOWER INTO
AND AN UPPER INTO THAT WOULD LET YOU DO
SMALLER-GRAINED MANIPULATION THAT IS WROTE
DIRECTLY TO YOUR NEW BYTEARRAY.
CAN THE MEMORY VIEW SAVE US, THOUGH?
IT DID IN ALL THE PREVIOUS OCCASIONS.
NO.
BECAUSE MEMORY VIEWS DON'T DO ANYTHING
STRING-LIKE.
THE MOMENT YOU MOVE TO A MEMORY VIEW WHICH LETS
YOU LOOK AT A PIECE OF STRING EFFICIENTLY, YOU'RE
NOT GOING TO BE ABLE TO DO ANYTHING STRING-LIKE
TO IT.
SO YOU HAVE TO DO A ROUND-TRIP OUT TO A SMALLER
STRING TO DO A MANIPULATION AND STORE DATA BACK.
TO MUTATE A BYTEARRAY WITHOUT REWRITING ITS WHOLE
CONTENT, YOU'RE GOING NEED INDICES.
DO YOU REMEMBER INDEX EBBS?
BACK THE FIRST WEEK BEFORE YOU FOUND STRIP, SPLIT
AND JOIN, AND WERE DOING EVERYTHING LIKE THIS,
YOU GET TO DO IT AGAIN IF YOU DECIDE TO TRY
MUTATING A BYTEARRAY.
THE BYTEARRAY WILL LET YOU ENJOY THOSE DAYS ALL
OVER AGAIN BECAUSE ALL THE MUTATION OPERATIONS
ARE POWERED ONLY BY INDICES.
ONE HINT, REGULAR EXPRESSIONS, WHILE THEY TURNED
OFF A LOT OF OTHER STRING-LIKE THINGS WERE LEFT
TURNED ON AND DO WORK AGAINST BYTEARRAYS AND CAN
HELP GIVE YOU SOME USEFUL INDICES TO USE.
FREESTYLE MUTABLE STRING, IT'S AWKWARD.
I HAVE HERE AT THE END OF THE SLIDES SOME LINKS
TO OTHER DOCUMENTATION, INCLUDING THE BLOG POSTS
THAT INSPIRED THIS TALK AND MAYBE WANT TO BRING
EVERYTHING TOGETHER IN ONE PLACE AND IN
CONCLUSION, THE BYTEARRAY, IT IS A VERY
MEMORY-EFFICIENT, NOT FASTER BUT MEMORY-EFFICIENT
STORE OF BYTE INTEGERS, SHOULD YOU EVER NEED
THEM.
IT CAN HELP CONTROL MEMORY IMPLEMENTATION WHEN
DOING HIGH-PERFORMANCE IO BECAUSE YOU DON'T HAVE
TO CREATE A NEW STRING BUT IT'S HARD TO MAKE IT
FASTER IN A RELIABLE WAY.
BE CAREFUL.
IT'S A GREAT WAY TO ACCUMULATE DATA THAT'S COMING
IN A PIECE AT A TIME.
THAT'S ITS REAL SUPER POWER, AND EVEN THOUGH IT'S
TEMPTING FOR STRING OPERATIONS, IT'S A BIT
UNDERPOWERED AND A BIT AWKWARD.
THAT'S WHAT I'VE LEARNED SO FAR.
THANK YOU VERY MUCH.
[ Applause ]
>> WE ARE OUT OF TIME, SO I WILL MEET BYTEARRAY
INTERESTED FANS OUTSIDE THE DOOR IN A FEW
MINUTES.
03:54:10