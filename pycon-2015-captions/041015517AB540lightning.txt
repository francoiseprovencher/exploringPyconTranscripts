  
  >> All right, how is it going folks?
  [Applause]
  Whoo!
  Wow, come on, you can do better than that.  One more time.  Yeah?
  Whoo?
  I'm a bit fragmented I guess.  Welcome to lightning talks, yeah.  I hope you're excited.  Lot of people enjoy this part and I enjoy being up here.  So, I am Lynn, this is second year of hosted lightning talks and pretty much like have lot of fun up here because I can tell really bad jokes.  But unfortunately I didn't prepare that much for you but I'll be better tomorrow morning, I promise.  But it's a lot less stress up here I have to admit because it's kind of if you to talk to these folks and, I don't know, hopefully not scare them too much before their talk.  But I wanted to give an actual talk this year, but I'm thankful because it's far less stressful like this whole thing is far less stressful.  Probably for the better because usually my talks, my style of preparing for talks is more like conference-driven development.  Because I propose an idea and if it gets accepted I'm like, crap, I actually have to do it.  Then procrastination I'm preparing the last week.  I'm not that stressed this year.  And then my talks kind of turn into -- like you have speaker notes, some nice crutch turns more into a dramatic reading rather than a talk.  So, anyways, since I have the podium right now I want to do a couple of announcements.  Some of you might know me from PyLadies.  And so I want to give couple of announcements regarding PyLadies.
  I wanted to thank sponsors, because with sponsors and actually a lot of individual contributors PyLadies was able to raise $40,000 for women in financial aid that's pretty awesome.
  [Applause]
  And companies like new Relx, SurveyMonkey, Caktus all donated I'm so super thankful for that.  We have some you a event events tomorrow night 6:30 is the auction.  We have some really cool stuff, you might have heard of the 26-pound gummy snake -- I -- I hope -- I hope someone local takes that because I would hate to that I that on your carry on or something.  We also have a print from Disney's "Big hero 6" on display at the PyLadies booth, check it out.  And there's some pretty awesome, like Python like print socks and like a tie.  So that seems awesome.  I'm totally going to bid on the socks.  If anyone outbids me, we're going to Duke it out.  You can still donate to the auction if you have an item to donate you can contact me at  Lynn@Pyladies dot.com.  This floor, I think right around the corner is lunch.  I encourage you to come because we have a little like gift for everyone.  So, not much but it's cute.  If you're around lunch time you're a woman of PyCon I want to you come.
  Lastly, come visit our booth by PyLadies T-shirt last year at this time we sold out of PyLadies T-shirts and we got more this year but we have a lot left it's kind of sat.  Makes me sad.  Go buy a T-shirt be awesome.  Yeah, those are all the PyLadies' events that I have.  Wait, two more I completely forgot.  There's a super awesome geeky GPG key signing party at some open space, I will announce it on the PyLadies' Twitter.  I have to find the space and time but I think it will be Sunday.  Come be geeky with us sign our keys.  Then PyLadies is also hosting a sprint.  All right.  Who is ready for lightning talks?
  [Applause]
  Okay.  First up we have Stefan talking about extensions with -- let's give a hand.
  [ Applause ]
  >> Yes, hello everybody I'm Stefan Richthofer my program is -- names my efforts to at extension C extension support to -- I know you don't want to hear this but sometimes Java is nice language.  May it be because of multi-threading because of type safety or maybe just because you have to use an existing framework.  Whatever with Jython you won't have to make this decision.
  You can do what needs to be done in Python, what needs to be done in Java they are hardly boundaries except you depend on CPython extensions.
  Java offers a way for extensions which is called JNI, Java native interface.  It's basically Java extension that pretends to be CPython regarding to CPython extensions.  How does it work.  This is a bit out of scope for a lightning talk but you can ask me for technical questions afterwards.  Basically it's about providing CPython compatible view on to the YJYthon, there are several reasons why this is not trivial mainly because of -- CPython uses macros the API is large and complex.  These things and absolutely major difficulty to prove clean garbage collection.
  I am using different approaches depending on the situation, sometimes a mirror it which works out synchronization issues because this is mostly necessary only for IMmuteable types.  For now I skip it here because rest is a bit technical instead to something dangerous.  Which is a live demo.
  Look at this little program.  By the way it's currently Linux only a friend tried to get it working on OS10 but Windows will be another beast but this will come but for now it's Linux only and it's things state, but example for popular extension that already works.  Take a program two buttons, one text feel, one button just prints to the text field the things demonstrates a java coil.  Just uses java Api system, it prints the current time stamp basically.  But it does get it from java.  Okay, note that the import here is done in the method, don't do this it is just done so that CPython also can run this.  And doesn't crash immediately.  Okay, this is with CPython this one works, of course, but clicking this, CPython doesn't know what to do with the java import, of course.  Okay, quit it.  Using ordinary java for it.  Doesn't work at all.  Okay, this looks slow but it is just start-up time because java has to do just in time compilation and such things.  Okay, it doesn't know what to do with this import.  Note that I edit the entire path for Linux, this points to the actual CPython, do not make library of that.  You don't have to modify the program at all to use Jyni you just have to edit to the, this is the comment to do with this Jython, let's run it.  And now we will have program that neither Nython or CPython would be able to run perfectly.  Yes, it works.  I can also edit this here.  Now also the java stuff works as expected.
  [ Applause ]
  In the last ten seconds invite to learn C extension API.  Thank you for your attention.
  [ Applause ]
  >> Nice job.  Thank you.  Exactly the right time.  Up next we have Brian talking about multi-service async file streaming.  Give him a warm welcome.
  [ Applause ]
  Hello I'm a developer for the center for open science.  We are a non-profit Python development shop, we do exclusively free and open source software.  I'm talking to you today about waterbutler which we use on our flagship product the open science framework which is a CMS for scientists that is relatively workflow agnostic.  Many of the workflows that scientists use involve transferring files to and from a lot of different services.  The difficulty we have with this is that a lot of the OSF is synchronous.  Which means that if we say want to upload a file to DropBox then we have to wait and wait and wait and wait and wait and wait until it's done.  Until we can have that process back.  Which is terribly inefficient.  So, instead we have implemented an asynchronous service that will allow us to transfer a bit to DropBox and then switch over to a Google drive upload and switch over to another upload basically we can handle hundreds of simultaneous connections on the same service without significant loss in performance.  So, how this works, is let's take an example of download Lincoln the OSF that leads to an Amazon S3 file if you like you can image in this being your website and some things provider, it will work with anything that you want to use.  So they click on that link and that looks something like that.  We do a look-up and know that that's redistrict to our waterbutler server.  And it takes the parameters there and turns that into a Json blob.  That Json blob is sent over to our authentication server where we determine if the user initiating the download has access to that file or not.  If they don't their journey is over.  However, if they do, then everything becomes much more interesting.  We go and we take the users authentication information, the credentials for the service itself in this case like I said the Amazon S3 tokens.  And identifier for the item in this case the file that we are downloading.  We send that to waterbutler.  Which creates a constructs a provider object, in this case, an Amazon S3 object.  Which takes that provider's download method, takes the parameters from before and we have one of two options at this point.  The first is since it's S3 we can use Bot to, construct a signed S3 URL a redirect from the initial click we can connect the user directly to S3 for the download.  Our things option is we can stream the file.  So we can take a single packet at a time, transfer from S3 to the user and it all goes to the same place.  The user doesn't care how they got it.  The great thing about this is then we -- if you are doing upload it is essentially the same process.  We do not allow signed URLs for up loads for several reasons one we like to do multiple cryptographic Caches on the file and ensure that the file is correct.  But another nice thing is that we can take, say, if you had two different S3 buckets and you wanted to transfer a file from one bucket to the things, you can download from one bucket, stream it through our service, one packet a at a time in memory and send it to another S3 bucket.  Or if you want to get a little fancier you can do the same thing except, say, between DropBox and S3.  So, if you would like to learn more about this, drop by our website OSF.io/3winr.  That will have these presentation notes plus link to our repository with all of the code for waterbutler of course we'll be doing sprints on waterbutler love to see you there.  We'll be doing new providers and things to increase the goodness that is waterbutler.  Thank you very much.
  >> Good timing.  Nice job.  Next up we have Aaron Braswell talking about the share notification system.
  >> Hello, every one.
  [Applause]
  My name is Erin I'm also a developer at the center for open science much like Brian there.  And as he mentioned we're a non-profit also a Python Dev shop and we develop exclusively open source software for scientists also tools for developers to use, cool ones like waterbutler which is really fun.  But so the project that I work on is something called share, or share notify or the share notification system, it's all over the place now because it is under rapid development.  And so what share is there for is we work with a bunch of different organizations, libraries, research providers all sorts of people.  And what it's there for to take free scholarly metadata that already ex cysts in lots of public Apis all over the remember and different content providers and normalize that into one standard Json, some is in XML and after we're done it's one standardize dollars API with one metadata schema.  We take that, we -- these are our 30 providers that we have right now.  We are always looking to add more.  We're very interested in any providers that you all might have in mind in fact we're going to be here for the sprints and we will be sprinting on share in part.  So if you have a content provider in mind, like any of these, that has publicly accessible API come talk to us, come ask questions, come see if you can contribute, we'd love to talk to you about it.  So, we've built a pretty easy front end on top of all of that data just to show what a quick demonstration how it could be useful.  For example you can go to one place to find any data about frogs, for example.  Super Novi, cancer biology, Shakespeare or maybe even Python, if you are interested in research about Python.  Of course, that search yields results with links that all go back to the original source.  So you can see what they looked like in their original form.  Here's a preview of what that Json, Api looks like.  It's fully using syntax, and it also exposes the raw elastic search results so you can do really fast aggregations on that data and get interesting information out of it.  We also have an atom feed which is exact same metadata in a different format.  Lot of awesome tools to help make this happen including Python.  And Django.
  And it's a lot of fun put together.  So, what can you do with all of this data in one format?
  We would love to find out.  We would love to hear your ideas, we'll be doing sprints.  We're looking for librarians to curate the data, scientists and researchers to maybe use it to find related research to their's.  And/or developers to pull it together in interesting ways.  So, you can do many different things with it, what I decided to do it for the first time was to make a mark-off change generator using the ab tracts from a couple of different items in the service and you can see that from these two examples sometimes they're way more effective than others.  Kind of gets caught in a loop there a little bit.  But again, we would love to you contribute to share.  We'll be here for the sprints, all of our code on GitHub.  Under the center for open science/share.  And here is a link that you can go to to see all of these things that I've talked about and also any things lightning talks from people at the center for open science today.  Thank you.  That's it.
  [Applause]
  Ant6n.
  >> Thank you so much.  How do you work timers?
  All right.  Next up go over here now is hard to like juggle.  We have Ant6n, I'm sorry to mispronounce, talk about 13 facts about union code.
  Thank you.
  >> Any, I'm Ant6n.  I'd like to talk about code.  I only have five minutes it's really like subject like this.  So I will thinking about just picking couple of small things to tell people maybe learn something.  So, what is Unicode.  I hope this is what people know.  Union code is something that is meant to be able to represent all the word's languages in uniform way.  I mean, all the scripts of all the words languages.
  Every writing that currently exists and also that has ever existed.  It's meant to basically be uniform replacement to all sorts of things messy encodings that existed before, and union any code meant to represent all of the characters and all of these systems that existed before.  Although in the beginning it's mostly represents scripts because bunch of things encodings beforehand had little symbols in them these made it in too unicode strictly speaking like symbols, they're images that's basically what it comes from that's not really script, right?
  And I'm kind of -- happy to say that although wing dings are symbols they're not script now part of unicode 7.  You can represent these wingding, is that is terrible hack that Windows used to have in unicode 7.  So, what the way unicode represents characters is as a set of code points that are mapped to characters that you can see.  And these code points they're not really bytes or anything just numbers.  But if you want to talk about bytes, you actually need a separate layer of encoding that says, unicode character encoding provides a way to map from bytes to these code points.  So, bytes is data, then they represent -- there is a mapping that gives you code points which is just numbers.  Then unicode then can turn these into characters to be displayed on a screen.  And then of course you can go backwards that's called decoding.  So, some people may know they exist these encoding schemes like Utf-8.  They can represent code sequences these numbers that represent letters in some way.  We kind of know maybe that there is these -- that unicode character can be represented in one, two, three four bytes and Utf-8 all sounds very messy.  In reality this is not something we have to worry about as least in Python 3 bee have unicode springs where every -- it's actually unicode code point.  Once we read the data from that file where it comes in as bytes we have union today code points don't have to worry about how many bytes every character takes.  But there are some pitfalls.  First we have to understand when you talk about unicode see census they represent graphemes like a letter.  The official definition is minimally distinctive unit of writing in the context of a particular writing system.  So, the Latin alphabet will be letter A, B, C, Asian alphabets will be more complicated structures.  These are then represented by Glyph the image that represents a character.  Here possible Glyphs that represent the grapheme, A of the Latin alphabet.  The problem is, that you might have one letter being represented by multiple possible unicode code points or though you say, don't care about how many beats but might have two numbers that come together to represent one letter and this case, letter A which is used in German.  You also have it the things way around where you have one single code point representing actually multiple letters.  For example, in union code exists code point that represents the Latin small ligature Ff.  Also another one somewhere else that represents PPM that is physical unit and it's a legacy thing that came from some Japanese encoding system, I believe.  But it gets worse than that.  Oh, yes, what you have here sometimes may have character like that ligature of FF pop up in some text when you ask what is the length of it, although Python actually knows the length, Python knows about unicode will give you the wrong number of characters then you would expect.  Another issue is, that you actually have different characters, different -- same Glyph, be represented by different points, the Greek question mark likes like semicolon.  That's even worse.  You can also have the situation where the letter A is actually showing up in the unicode multiple times and many different ways.  There is such a large number of possible As.  Yes.  Anyway --
  >> I have to cut you off.  I'm sorry.  
  >> Some good news in all of this mess there is ways to represent unicode.
  This is something you should worry about more than how many bytes are represented by character.  I just want to say Unicode.  I wish I had more time.
  >> Thank you next up we have Catherine Devlin talking about SQLal come data points.  Let's her a warm welcome.
  >> Am I on?
  I am.  Hi, I'm Catherine Devlin I apologize lie live slide technology didn't work.  But I love databases, I hope you love them, too, I love SQL Alchomy, you know this, it's on sect relational mapper but it's a lot more than that.
  Like saying Montreal is a town in Canada.  Much more to it than that.  I find that it makes an amazing toolbox that let's me reach in to the database and do all sorts of interesting things.  Not just a toolbox it's a metatoolbox let's me build tools.  I'm going to show off just three of them that I've built SQL Alymony and inspire you to build your own based tools.  The first one is DDL generator the world is full of data unfortunately tragically much of it is not in a relational database.  A lot of ways to extract it and get into it a database, what there isn't a lot of ways to do is to set up the table structure, you end up always having to do that by hand it's a pain.  So DDL generator is a tool that will reach into a database, figure out what kinds of -- what would you need to define to get it into relational database then optionally give you the insert statements.  So the result is, that you can actually have a one liner, nothing up my sleeve, we are dropping and empty database creating it and populating it all in one line just by piping it in, in this case through PSQL.  One great tool.  Do you believe me that the data is in there?
  Don't believe me.  We're going to use another tool.  The SQL extension to IPython going to turn the wonderful IPython tool into a SQL clients.  Once you loaded SQL extension make the connection to your database, this is a standard SQL Alchomy extension stream, IPython turns into this wonderful query tool.  I might have had high file troubles when I was looking up birds in Canada.  In any case.  And this will let you do any kind of SQL that you can imagine the queries can get quite complex you can imagine more complex than that.  You can assign that to a Python variable and this variable you can use in a lot of ways, for instance you can get -- use data frame method get a data frame just like that you can do all the wonderful things you can do with a panda data frame like quick and easy plot.  Another -- once you've got data that you want to work with it's production data you need a test database.  The trouble is, that a good test database should really be true, it should be faithful to the production database.  But slicing out a chunk of your production database to use as a test database can like trying to take scissors and cut a little teeny sweater out of a big sweater without breaking any threads.
  [Applause]
  The answer is, very tediously but write a Python program to do it for you that's what RBDMS does.  All I'm doing, just emptying, contains just the table definitions, is I am asking sub setter to produce me a test database with roughly 10% of the original database.  And it trucks along, does it thing there is the same query only this time it is just plucking it out of the test database.  Maintained the relational integrity which can tell you which province each of these cities is in.  There is ton of tools in my head the trouble is I only have two hands to type with.  So you need to go to your DBA, teach them Python, tell them about SQL Alchomy we can have more wonderful tools and era of relational databases will go on forever.  Thank you very much.
  [ Applause ].
  >> Awesome.
  >> I tweeted this slide location.
  >> Great.  You're impressive.  Your slides broke then you're like, crap, then you just still went on, that's awesome.  All right.  So, next up.  Let's see I can get this timer running right.  We have Amjith talking about client with auto completion written in Python.
  >> All right.
  >> All right.  If anyone else hard pounding -- heart pounding?
  Let's get started before it explodes.  So, I'm here to talk about a side project I've been walking on a post -- that belongs in command line.  How many of you here use post?
  You guys all know how to use PSQL it's an awesome, I'm not complaining about that at all if I hit tab it completes.  But then it doesn't complete but that's okay.  After -- from it actually completes a little bit I have to hit tab couple more times then it does its think.
  Something like that.  And it works.  Now, that is a pretty good auto completion but I think we can do better.  So, I'm going to try exact same thing with MGCLI.  Let's get started.  You do select, star, from.  Then you start typing.  I don't even have to type I can just select one from the menu.  And after the where clause I get column names I can select one from the menu.  And I do the same thing.  It comes syntax highlighting.  That's how the completion should work.
  [ Applause ]
  Okay.  Thank you.
  [ laughter ]
  Py brain some of you might be thinking that's very simplistic statement, I mean it's rather easy to just go with a canned demo of some sort.  But it's not just a canned demo it works for most of the statements, so let's create a table.  Since I'm creative like that I'm going to name it "Demo" and let's have -- it definitely helps with typing because I'm not very fast typer.  I've created a new table, I'm going to insert some stuff into it.  And again, it starts recommending table names.  But the table we just created is also there.  So the auto completion automatically updates itself.  So let's insert some values.  And when I open a bracket it recommends what are the columns that I need to insert.  So, that's kind of what I had in mind for demos.
  You might also be wondering, auto completion is not everything, right?
  PSQL does a lot more it has back slash commands which are awesome I tried to emulate most of them so you can do backslash D it does that.  Or you can do backslash C to change a database and only recommends available databases in my current revision.  But I don't have anything.  I have a pretty good list but it's not as comprehensive as what PSQL does.  I that is where I need some help.  It is a very actively maintained open source project.  This is completely free so I would love for to you guys to just send requests, file issues, use them and let me know how it works out.  If you need more info to go PGCLI.com there are lot of screen shots, features, goes into a lot of detail how to use this and what are the different things that are available.  If you are MySQL fan you're probably lying because nobody is a fan of MySQL.  But you're probably forced by your company to use that.  So if you are wondering if there's equivalent of this, there is.  I am working on a project called MySQL-cli because I don't use it personally I need the motivation I'm doing a kickstarter for mysql-cli if you use MySQL, please support, I appreciate it.  Thank you very much.  That's all I have.
  [Applause]
  >> Thank you.  So I just went about this awesome new Python module.  I would love Python where else would we be here?
  It can do nearly everything right.  So, but doesn't think for us, right now, I guess.  But apparently there's some called Pybrain, maybe like import my brain, that would be awesome.  Goddammit, up next is Hubson lane, artificial neural nets for predicting whether using Pybrain.
  >> Indeed.  My name is Hobson lane from Portland.
  This is part of a project for sharp labs, we were developing neural nets to predict the power consumption in buildings.  But this little demonstration will use to predict the weather.  In Portland, Oregon, where it's impossible to predict F. I can get the slides to go.  Neural nets, as Melanie described to us, involved taking a bunch of inputs, whatever your features are, numeric then multiplying by some weights and combine them together and summing those multiplied values.  This is what -- it's basically linear algebra.  Multiply been a bunch of numbers in a vector and spit out another number.
  This is what those matrices look like on the inside after you've trained them they tend to build up some sort of a structure, this is a heat map so white is very large, maximum value.  Black is a very low value, you can see here interesting bit is that there's couple of values that are red which means in the middle which means they're close to zero which means you might be able to get rid of those neurons.  This particular network had six neurons, so, there's six possible output weights that are used to multiply by those coming out of the big matrix.  And so you can -- reduce to four, see what happens.  Then you might get a better result, more general result, typically when you have too many neurons you over fit.  In this case, I've built up on open scores side I've built up a set of helpers for Pybrain to make this easier to take your panda's data frame to tell it what column you're trying the fit to as output and you can train it to give it the number of neurons you want and away you go.  This is for the Python user group, we call it Pug, in Portland, Oregon and this is also has data to use all sorts of machine learning experiments on.  So that's how you would import that library and get data frame of weather from Portland, Oregon.  Then for so this is what this library does.  It just -- sets up input layer, it adds -- does all the little -- details in Pybrain that you have to do to make all the connections and make sure they're connected, if you miss one, you'll end up with -- end up with a broken wire.  And of course that doesn't give you your answer.  So, this just goes through all those steps properly for you.  And then if you want to create a dataset that's another tricky element that Pybrain does awesome job of.  It automatically divides up your set into training set and test set or validation.  Just tell it how much of your data you want to use for each and away it goes.  But in order to turn a data frame into a dataset you need another helper function and that's what this does.  So, this is the results for just did this about five minutes ago, trying to predict the weather in Portland, Oregon it looks good at this scale, this is after about 500 epics they call it in Pybrain attempts at back propagation to converge to a solution.  That looks great at this scale, at least getting sort of -- ignore the temperature F, I did this from here in Canada it actually -- data came across, weather underground knew I was in Canada it gave me the temperatures in degree C, I think.  This is over multiple years.  Each one of these is a day.
  This is over the past two years.  So, if you zoom in you see this not quite so great.  I still got some work to do on tuning this neural net like I said, one of the ways to go about that to eliminate some neurons or add new inputs to the dataset.  Currently the inputs were just the Min and max temperature the previous three days also the pressure, because I see weather people all the time talking about the pressure maps, so I figured that would be a good thing for this brain to use as its input.  But apparently needs to be some more inputs some ideas there might be neighboring cities, for instance, that -- particularly cities weather precedes the target city.  That's what I have.  This is a great library, I'd love your contributions, love to get pull requests, happy to incorporate them feel free to use it and apply for whatever problems you have with neural nets.
  [Applause]
  >> Awesome.  Thank you.  I just realized that there is closed captioning I hope they didn't catch my swear word.  Next up we have Matt Balhmann talking about Diff-cover, one pull request at a time.
  >> that's right.  Howdy PyCon.
  We'll talk about Diff-cover we all just got hired to work on the back computer.  First thing, we'll look at the code, that's fine but not too important first thing we'll do is run the tests.  Oh, Batman does not write tests we have coverage of 38%.  Holy untested code, Batman, what are we going to do?
  We ought to write tests for this code, obviously.  Batman sad to hear.
  This but let's talk reality for a moment.  You saw that code, that's a bunch of code.  We can't write tests for all that code.  It's invisible we don't necessarily all that, Batman is a complicated guy, we see code, we write tests against code best we can.  They might be inaccurate, might be fragile.  So really what we want to do at least be good going forward because we hopefully that code works fairly well, Batman has been using it.  So this is where Diff-cover comes in the idea that we run coverage reports but only really the changes in your branch.  So it takes the branch you're working on compares it to a target branch that way get coverage report that is just on the line you currently changed.  So, let's write a new feature we write some code about things.  Doesn't really matter too much although fun to read.  And if we were to simply just run a coverage report, we see that the coverage went up, hey, good.  It's very easy to stop there say, what, coverage got better, what's your point?
  However, if you were to run Diff-cover what you would notice is that you are only really covering 50% of the new code you wrote.  So, yeah, things got better but you're not helping by not writing test for new code because we're trying to go getter going forward.  What do we do?
  Write more tests, obviously.  But superstitious and cowardly lots they will show themselves.  And developers they need to fight against chaos and good tests are critical tool to fight chaos.  We write from tests, we run it again, coverage of 100%, happy Batman.  Code gets merged, the project is better than you found it and Batman is pleased that he it's tested that's awesome.  So, the time I have remaining talk about separate tool, same basic idea called Diff quality what this does run static analyzes like pep 8, over the Diff.  Does static analysis basically.  So if I were just to run pep 8 over Batman's code the man fights crime, he doesn't write code.  My God.  But, okay.  When I run Diff cover I can see, wow, apparently I don't know how to write code either.  There is tabs in there, there is mixtures, but at least I know I need to fix this.  I can worry about that stuff when I touch it.  Couple more features I want to talk about we have fail under, if a Diff cover or Diff quality report gives you coverage and certain percentage, fail it.  What this is for if you integrate Diff cover into your CI you can fail it if you make PR that just doesn't fit your standards.  And then we have HTML reports.  Like, boom.  Something about cats.  Should probably cover that line make sure that we have that mode of correct.  And similar report for Diff quality.  And that's basically the idea.  I went through that a lot faster than I thought I would I'd like to give acknowledgments out here.  Diff cover was written by Daly and originally written by Serena they wrote this while working for Edux I'm currently the maintainer of the project it's hosted on my account so there is code there.  It's easily installed.  If used by Edx I few things organizations using it and love it.  I also use it where I work.  Company named cloud lock, look it up, it's cool.  And if you need slides, if you need me, I'm there.  I got a minute left.  We can do some knock-knock jokes.
  [Applause]
  >> Thank you very much.  All right.  Score.  Right on time.  Next up we have Andrea.  Talking about inspiring kids and teenagers to enter the programming world in Peru.
  >> Hi, guys.  I am going to talk about how women technology inspiring kids to enter the programming world and how we organize the first Pycamp what you can do to do similar event anywhere in the world.  A little bit about women technology Peru it got founded in 2013.  Since then we have organized more than 30 events.  We have 1600 members on Facebook.  And we have reached more than 1,000 during all these events.  So, last year I came to my first Pycamp I was amazed by everything that was being done by kids using Python.  I applied for software foundation grant we got the grant we were able to found this event using these.  This was a one-day workshop where 24 teenagers including boys and girls attended.  And for these workshops used young coder tutorial.  Translated from English to Spanish we adapted it, we changed peanut butter and jam example to avocado sandwich because it doesn't work with us.  Lessons learned that's what you can take home if you want to organize this event you can do it.  So, the first one is collaboration is key.  We didn't know each things for the event, like the coaches and women technology Peru we had never met before.  We started organizing this event four months before the event, so we met shortly before, hang out every week almost, I he -- on e-mail like collaboration works for these types of events.  It was great that we were able to separate the responsibilities between coaches and organizers, and that the coaches had diverse backgrounds, we had math teachers, engineers and so on.  The second one is that you need to know your audience.  This was the most painful lesson for us.  Teenagers do not check e-mail that's something that we learn during this event.  So when we sent invitations back to the teenagers, we said, RSVP for this event, we didn't get confirmation back you need to know your audience.  These are going to be mildly motivated teenagers that will attend your events you need to know that.  Lightning talks like these are effective, kids get a chance to hear from people that are really using Python on their daily lives.  How they are using it, and what they can do with those tools.  And seek mentors, I was able to talk with somebody that had organized a similar event in North Carolina and talking with her and learning the lessons that she already knew was really helpful.  So, seek mentors that can help you doing these things.  So, the outcome for this event was very successful.  The ranged us very high, one of the thing that they said, how we can improve this event was that they told us, do not take so many pictures of us, we were really, really not flattered by that.  Be careful on the picture side.  But things than that, they really enjoyed the event.  They said that they would attend another one, they would tell their friends about it.  And actually like many of the girls that attended the event continued into a summer program after this event in to learning things tools.  So, the last phrase that I am going to leave with you is, I am not telling you that it's going to be easy, because it's not there are many times that we wanted to quit and stop organizing things, but it's worth it.  Last week one of the girls that had attended many of the workshops was interviewing the television and just seeing her grow and all that things students that we have, has been great.  So, it's worth it.
  
